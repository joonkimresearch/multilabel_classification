{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Multilabel_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DHnWDRnMjTRM",
        "0EckauKFzkUC",
        "LpQ1g1QPjaDg",
        "5J5BSD6VCCkL",
        "NsgFnpmZFmFp",
        "HSLMahkZF5QO",
        "2W-iCT9UeKtZ",
        "ZfA5QwqbRbQR",
        "yuewCsDK-ieK",
        "KzCUFunEjbku",
        "MfssW72u3DEK",
        "XIly3aG63IPQ",
        "Pll7RIl93L6E"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multilabel classification with BERT\n",
        "1. Goal\n",
        "  - Build a model that predicts tags (keywords) of articles published on arxiv.\n",
        "  - Compare different solutions for class imbalance problem and multilabel classification problem. Specifically: \n",
        "    - Sampling methods: LPROS vs. MLROS. \n",
        "    - Multilabel classification: binary relevance vs. classifier chain vs. KNN vs. deep learning\n",
        "\n",
        "2. Data: Abstracts published in academic journals https://www.kaggle.com/spsayakpaul/arxiv-paper-abstracts?select=arxiv_data.csv\n",
        "\n",
        "3. Class Imbalance\n",
        "  - The dataset is imbalanced when the occurrence of each label is not equal. In this project, I used the label powerset random oversampling and multilabel random oversampling methods. The LPROS and MLROS approaches are chosen because two methods outperformed other techniques in a recent article ([Terekegn et al., 2021](https://www.sciencedirect.com/science/article/pii/S0031320321001527))\n",
        "\n",
        "4. BERT\n",
        "  - Bidirectional Encoder Representations from Transformers (BERT) is a transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google ([Devlin et al., 2018](https://arxiv.org/abs/1810.04805)). A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data.\n",
        "\n",
        "5. Binary Relevance vs. Classifier Chain\n",
        "  - Binary relevance approach works by building an independent binary classifier for each class. \n",
        "  - Classifier chain approach works by buidling a binary classifier for each class. The classifier for class i uses predictions from classifier class j where i > j. \n",
        "\n",
        "6. MLKNN\n",
        "  - ML-KNN is derived from the traditional K-nearest neighbor (KNN) algorithm. For each unseen instance, its K nearest neighbors in the training set are firstly identified. After that, based on information gained from the label sets of these neighboring instances, maximum a posteriori (MAP) principle is utilized to determine the label set for the unseen instance ([Zhang & Zhou, 2007](https://www.sciencedirect.com/science/article/pii/S0031320307000027))."
      ],
      "metadata": {
        "id": "CCUXzsOYjOFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "DHnWDRnMjTRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To run KNN, 0.24.1 is required \n",
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "id": "wh2I3eZ_UDLr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e7a30507-6e79-499f-948a-3e87d4acdaf9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.24.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-JBOa5AejLvZ"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import scipy.sparse\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, hamming_loss\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from ast import literal_eval\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2phHYfgGnZhz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "j4tAp03jFJgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kaggle"
      ],
      "metadata": {
        "id": "0EckauKFzkUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "gM2OazX8jX1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "QOti4IQ4k6hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "3T_TdbDAl0iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "eg_7o7i_lC01"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vjbXIZgGlGDo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d spsayakpaul/arxiv-paper-abstracts"
      ],
      "metadata": {
        "id": "9az07jBSl9vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip arxiv-paper-abstracts.zip -d kaggle"
      ],
      "metadata": {
        "id": "2sW2Kg-jmnWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/kaggle/arxiv_data.csv\")"
      ],
      "metadata": {
        "id": "UeoEae0Bmwnb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ja-4YKJkoR4q",
        "outputId": "ae133d8a-0b76-46cd-d751-f9892ee6d91e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51774, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d848d395-8479-4ba8-b49d-87cda7cf07cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d848d395-8479-4ba8-b49d-87cda7cf07cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d848d395-8479-4ba8-b49d-87cda7cf07cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d848d395-8479-4ba8-b49d-87cda7cf07cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_duplicate_titles = sum(df[\"titles\"].duplicated())\n",
        "print(f\"There are {total_duplicate_titles} duplicate titles.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmVHuqSuUabe",
        "outputId": "be73c037-db25-4cef-ac64-e04ad4ba65fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 12802 duplicate titles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~df[\"titles\"].duplicated()]\n",
        "print(f\"There are {len(df)} rows in the clean dataset.\")\n",
        "# Select samples\n",
        "df = df.sample(n = 5000, random_state = 1)\n",
        "# Choose the column \n",
        "df = df[[\"summaries\", \"terms\"]]"
      ],
      "metadata": {
        "id": "znaxPwU-sMUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0129a50e-a8c4-41a7-dff1-0696447b37db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 38972 rows in the clean dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Relevance, Classifier Chain, MLKNN \n",
        "### Preprocessing"
      ],
      "metadata": {
        "id": "LpQ1g1QPjaDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filtering"
      ],
      "metadata": {
        "id": "5J5BSD6VCCkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list of strings to lists \n",
        "df['terms'] = df['terms'].apply(lambda x: ast.literal_eval(x))"
      ],
      "metadata": {
        "id": "C48gBJrju59Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of unique keywords in \"Terms\" column\n",
        "print(df['terms'].explode().value_counts()[0:10])\n",
        "print(\"Number of unique terms:\", len(df['terms'].explode().unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CAikWdcoRSu",
        "outputId": "7a6fe949-b091-47c3-cd5c-3fface49a36a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cs.CV      2854\n",
            "cs.LG      2826\n",
            "stat.ML    1573\n",
            "cs.AI       729\n",
            "eess.IV     214\n",
            "cs.RO       208\n",
            "cs.CL       138\n",
            "cs.NE       136\n",
            "cs.CR        77\n",
            "math.OC      77\n",
            "Name: terms, dtype: int64\n",
            "Number of unique terms: 273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose top 5 keywords \n",
        "from collections import Counter\n",
        "top_terms_list = Counter(list(df['terms'].explode())).most_common(5)\n",
        "top_terms = [a_tuple[0] for a_tuple in top_terms_list]\n",
        "top_terms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcAqkbxFvm9r",
        "outputId": "dd1b32b0-262f-4a7b-af81-87a7bfca8803"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['terms'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EONjY0OY2a1F",
        "outputId": "5ae54b02-4db3-497f-cd36-11dca7a88e6a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1342                                               [cs.CV]\n",
              "19326                                       [cs.CV, cs.AI]\n",
              "22098    [cs.LG, physics.app-ph, physics.chem-ph, physi...\n",
              "48541                                [cs.LG, cs.AI, cs.SE]\n",
              "12544                                       [cs.CV, cs.LG]\n",
              "Name: terms, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "u5mxycZs3mNJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out records that have at least one of the top keywords\n",
        "x = [] # To store the filtered text (features)\n",
        "y = [] # to store the corresponding terms (labels)\n",
        "\n",
        "for i in range(len(df['terms'])):\n",
        "    temp = []\n",
        "    for term in df['terms'][i]:\n",
        "        if term in top_terms:\n",
        "            temp.append(term)\n",
        "\n",
        "    if(len(temp)>0):\n",
        "        x.append(df['summaries'][i])\n",
        "        y.append(temp)"
      ],
      "metadata": {
        "id": "CWvd5S4n3DDA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One Hot Encoding: Individual Labels"
      ],
      "metadata": {
        "id": "NsgFnpmZFmFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer() \n",
        "yt = mlb.fit_transform(y)\n",
        "yt.shape"
      ],
      "metadata": {
        "id": "JPvvkVMj00_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7c7bfd-1276-474a-b450-4525fda7b988"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqbzo7Zr_dPz",
        "outputId": "9b3ab6bf-ede8-4508-e9da-6e5d1c9c978f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 0],\n",
              "       [1, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build a dataframe with the feature (text) and labels \n",
        "df_filtered = pd.DataFrame()\n",
        "df_filtered['text'] = x\n",
        "df_labels = pd.DataFrame(yt, columns = top_terms)\n",
        "df_filtered = pd.concat([df_filtered, df_labels], axis = 1)"
      ],
      "metadata": {
        "id": "J882DPw0AoCS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Label Powerset "
      ],
      "metadata": {
        "id": "HSLMahkZF5QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add label powerset \n",
        "df_filtered['powerlabel'] = df_filtered.apply(lambda x : 16*x['cs.CV']+8*x['cs.LG']+4*x['stat.ML']+2*x['cs.AI']+1*x['eess.IV'],axis=1)\n",
        "\n",
        "# Create a histogram to confirm data imbalance \n",
        "df_filtered['powerlabel'].hist(bins=np.unique(df_filtered['powerlabel']))"
      ],
      "metadata": {
        "id": "gKCLypOqwPWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "4ca570f3-43be-402c-d1b5-97d743bb0ab1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa2029e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rtbQ5v53AsYF",
        "outputId": "e15c72ef-d75f-441c-e1f2-62a47f8a1e09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  cs.CV  cs.LG  stat.ML  \\\n",
              "0  This report describes the design, implementati...      0      1        0   \n",
              "1  Recent advances in document image analysis (DI...      1      1        0   \n",
              "2  Bayesian optimization (BO) is a popular paradi...      0      0        1   \n",
              "3  Learning algorithms produce software models fo...      1      0        1   \n",
              "4  Capsules are the name given by Geoffrey Hinton...      0      1        1   \n",
              "\n",
              "   cs.AI  eess.IV  powerlabel  \n",
              "0      0        0           8  \n",
              "1      0        0          24  \n",
              "2      0        0           4  \n",
              "3      0        0          20  \n",
              "4      0        0          12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c3ea4b4-447b-4a29-acd6-d27a85c30950\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cs.CV</th>\n",
              "      <th>cs.LG</th>\n",
              "      <th>stat.ML</th>\n",
              "      <th>cs.AI</th>\n",
              "      <th>eess.IV</th>\n",
              "      <th>powerlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This report describes the design, implementati...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Recent advances in document image analysis (DI...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bayesian optimization (BO) is a popular paradi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Learning algorithms produce software models fo...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Capsules are the name given by Geoffrey Hinton...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c3ea4b4-447b-4a29-acd6-d27a85c30950')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c3ea4b4-447b-4a29-acd6-d27a85c30950 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c3ea4b4-447b-4a29-acd6-d27a85c30950');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train-test split"
      ],
      "metadata": {
        "id": "2W-iCT9UeKtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df_filtered, test_size = 0.3, random_state = 1)\n",
        "train = train.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "x_yMkuiZCuW5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U61cZ5Q_BWjU",
        "outputId": "8853a00c-e2a2-4b0f-d622-44c401402966"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  cs.CV  cs.LG  stat.ML  \\\n",
              "0  Today deep convolutional neural networks (CNNs...      0      1        0   \n",
              "1  In the paper, we propose a class of efficient ...      0      0        1   \n",
              "2  The generative adversarial network (GAN) exhib...      0      1        1   \n",
              "3  Though convolutional neural networks are widel...      1      1        0   \n",
              "4  In recent years, advances in the development o...      0      1        0   \n",
              "\n",
              "   cs.AI  eess.IV  powerlabel  \n",
              "0      0        0           8  \n",
              "1      0        1           5  \n",
              "2      1        0          14  \n",
              "3      0        0          24  \n",
              "4      0        0           8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1988154-a98a-4b16-a026-720b9d240b27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cs.CV</th>\n",
              "      <th>cs.LG</th>\n",
              "      <th>stat.ML</th>\n",
              "      <th>cs.AI</th>\n",
              "      <th>eess.IV</th>\n",
              "      <th>powerlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today deep convolutional neural networks (CNNs...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the paper, we propose a class of efficient ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The generative adversarial network (GAN) exhib...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though convolutional neural networks are widel...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In recent years, advances in the development o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1988154-a98a-4b16-a026-720b9d240b27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1988154-a98a-4b16-a026-720b9d240b27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1988154-a98a-4b16-a026-720b9d240b27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LP-ROS (Label Powerset Random Oversampling)\n",
        "- The Label Powerset transformation method transforms the multilabel data into a multi-class dataset, processing each different combination of labels (label-set) as a class. In other words, label powerset approach converts a multilabel classification problem into a multiclass classification problem. \n",
        "- LP-ROS (Label Powerset Random Over Sampling) is a multi-label random oversampling method that works by cloning random samples of minority label-sets until the size of the multilabel data increases by the prespecified percentage.  \n",
        "- In this notebook, we set the number of minority labels to equal to the number of the majority label. \n",
        "- Reference: [Imbalanced Multilabel Scene Classification using Keras](https://medium.com/the-owl/imbalanced-multilabel-image-classification-using-keras-fbd8c60d7a4b) "
      ],
      "metadata": {
        "id": "ZfA5QwqbRbQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lpros = train.copy()"
      ],
      "metadata": {
        "id": "SVRg-sAPTxsc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "powercount = {}\n",
        "powerlabels = np.unique(train['powerlabel'])\n",
        "for p in powerlabels:\n",
        "    powercount[p] = np.count_nonzero(train['powerlabel'] == p)\n",
        "\n",
        "maxcount = np.max(list(powercount.values()))\n",
        "for p in powerlabels:\n",
        "    gapnum = maxcount - powercount[p]\n",
        "    #print(gapnum)\n",
        "    temp_df = train.iloc[np.random.choice(np.where(train['powerlabel'] == p)[0], size = gapnum)]\n",
        "    train_lpros = train_lpros.append(temp_df, ignore_index=True)\n",
        "    \n",
        "#train_lpros = train.sample(frac = 1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "lDe5pUJWRc0e"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lpros.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY95AQi7SxOa",
        "outputId": "f4802722-d932-4eed-9ea6-9daf79208150"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29414, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "powercount_lpros = {}\n",
        "powerlabels = np.unique(train['powerlabel'])\n",
        "for p in powerlabels:\n",
        "    powercount_lpros[p] = np.count_nonzero(train_lpros['powerlabel'] == p)\n",
        "powercount_lpros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU2tdVOgWyXa",
        "outputId": "bed4d2b8-3c85-47c0-cc88-ad9bc80cf4a8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 1337,\n",
              " 4: 1337,\n",
              " 5: 1337,\n",
              " 6: 1337,\n",
              " 7: 1337,\n",
              " 8: 1337,\n",
              " 9: 1337,\n",
              " 10: 1337,\n",
              " 11: 1337,\n",
              " 12: 1337,\n",
              " 13: 1337,\n",
              " 14: 1337,\n",
              " 15: 1337,\n",
              " 17: 1337,\n",
              " 20: 1337,\n",
              " 21: 1337,\n",
              " 24: 1337,\n",
              " 25: 1337,\n",
              " 28: 1337,\n",
              " 29: 1337,\n",
              " 30: 1337,\n",
              " 31: 1337}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ML-ROS (Multilabel Random Oversampling)\n",
        "\n",
        "- ML-ROS is an approach based on the frequency of individual labels, instead of the full label-sets. \n",
        "- ML-ROS relies on IRLbl (imbalance ratio per label) and MeanIR (mean imbalance ratio) measures. Labels whose IRLbl is greater than MeanIR are considered to be minority labels, while labels whose IRLbl is smaller than MeanIR can be considered to be majority labels.\n",
        "- In the current notebook, we use the ML-ROS technique that uses IRLbl and MeanIR to identify majority and minority labels ([Charte, 2018](https://arxiv.org/pdf/1802.05031.pdf)). "
      ],
      "metadata": {
        "id": "yuewCsDK-ieK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate Mean IR and IRLbl\n",
        "def IRLbl(labels):\n",
        "  \"\"\"Takes a 2d array of labels and returns a list of the imbalance ratio per label. \n",
        "  imbalance ratio per label: (the number of instances of majority label) / (the number of instances of a specific label)\n",
        "\n",
        "  Input:\n",
        "    labels: a 2d numpy array. Each row is one instance, each column is one class; the array contains (0, 1) only\n",
        "\n",
        "  Returns:\n",
        "    irlbl: imbalance ratio for each label \n",
        "  \"\"\"\n",
        "  N, C = labels.shape\n",
        "  pos_nums_per_label = np.sum(labels, axis = 0)\n",
        "  max_pos_nums = np.max(pos_nums_per_label)\n",
        "  return max_pos_nums / pos_nums_per_label\n",
        "\n",
        "def MeanIR(labels):\n",
        "  \"\"\"Takes a 2d array of labels and returns the mean of imbalance ratios. \n",
        "  Input:\n",
        "    labels: a 2d numpy array. Each row is one instance, each column is one class; the array contains (0, 1) only\n",
        "\n",
        "  Returns: \n",
        "    mean of imbalance ratios: integer \n",
        "  \"\"\"\n",
        "  IRLbl_VALUE = IRLbl(labels)\n",
        "  return np.mean(IRLbl_VALUE)"
      ],
      "metadata": {
        "id": "Ih3CtZUb_M7y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def ML_ROS(df, labels, max_clone_percentage=50):\n",
        "  \"\"\"\n",
        "  Algorithm: https://arxiv.org/pdf/1802.05031.pdf\n",
        "  Reference: https://github.com/Bupenieks/ImbalancedMLC/blob/master/dataset_metrics.ipynb  \n",
        "  \"\"\"\n",
        "  # N of samples to clone, obtain the set of labels\n",
        "  labels_df = df[labels]\n",
        "  N, C = labels_df.shape\n",
        "  num_samples_to_clone = N / 100 * max_clone_percentage\n",
        "  print('Number of samples to clone:', num_samples_to_clone)\n",
        "\n",
        "  # for each label, add samples to the minority bag if the IRLbl < MeanIR\n",
        "  minority_classes = []\n",
        "  MeanIR_value = MeanIR(labels_df)\n",
        "  IRLbl_value = IRLbl(labels_df)\n",
        "\n",
        "  df_idx = df.index\n",
        "  map = {}\n",
        "  for l in labels:\n",
        "    l_indices = df_idx[df[l] == 1].tolist()\n",
        "    map[l] = l_indices\n",
        "    min_bags = {l:ins for l, ins in map.items() if IRLbl_value[l] > MeanIR_value}\n",
        "  print('Minority label:', min_bags.keys())\n",
        "\n",
        "  # Clone a random sample from each minority bag\n",
        "  new_df = df\n",
        "  while num_samples_to_clone > 0:\n",
        "    for l in min_bags:\n",
        "      instance_to_clone = random.choice(min_bags[l])\n",
        "      new_df = new_df.append(df.iloc[instance_to_clone])\n",
        "      new_IRs = IRLbl(new_df[labels])\n",
        "      new_IR_l = new_IRs[l]\n",
        "\n",
        "    if new_IR_l <= MeanIR_value:\n",
        "      # Exclude from cloning\n",
        "      del min_bags[l]\n",
        "                        \n",
        "    num_samples_to_clone -= 1\n",
        "\n",
        "    if len(min_bags.keys()) == 0:\n",
        "      print(\"Unable to clone all samples. {} left to clone\".format(num_samples_to_clone))\n",
        "      break\n",
        "\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "1oWTe0n3HwYd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['cs.CV',\t'cs.LG',\t'stat.ML',\t'cs.AI',\t'eess.IV']\n",
        "train_mlros = ML_ROS(train, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtNeSRK9T3lv",
        "outputId": "2147ac82-b5cb-4fab-c458-4d7940b5515b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples to clone: 1750.0\n",
            "Minority label: dict_keys(['cs.AI'])\n",
            "Unable to clone all samples. 1322.0 left to clone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mlros.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB8gOnX7c4Ah",
        "outputId": "f1b96803-5274-4dfe-8ec1-20e48db95190"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3928, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(MeanIR(train[labels]))\n",
        "IRLbl(train[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOez-mrolRxs",
        "outputId": "59bf5074-41de-40c1-e961-35f7a445d04b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.139988862143587\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cs.CV       3.875486\n",
              "cs.LG       1.000000\n",
              "stat.ML     1.000502\n",
              "cs.AI      13.019608\n",
              "eess.IV     1.804348\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(MeanIR(train_mlros[labels]))\n",
        "IRLbl(train_mlros[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu5hhe5AlNtb",
        "outputId": "4ca32a50-876e-45fa-e766-c704b135118a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.574434639427914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cs.CV      4.570342\n",
              "cs.LG      1.000000\n",
              "stat.ML    1.060900\n",
              "cs.AI      4.137694\n",
              "eess.IV    2.103237\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lpros.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S7WcUde8lulP",
        "outputId": "99abe0c8-fdb9-47fa-d948-abd20e07e824"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  cs.CV  cs.LG  stat.ML  \\\n",
              "0  Today deep convolutional neural networks (CNNs...      0      1        0   \n",
              "1  In the paper, we propose a class of efficient ...      0      0        1   \n",
              "2  The generative adversarial network (GAN) exhib...      0      1        1   \n",
              "3  Though convolutional neural networks are widel...      1      1        0   \n",
              "4  In recent years, advances in the development o...      0      1        0   \n",
              "\n",
              "   cs.AI  eess.IV  powerlabel  \n",
              "0      0        0           8  \n",
              "1      0        1           5  \n",
              "2      1        0          14  \n",
              "3      0        0          24  \n",
              "4      0        0           8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c0a9b93-6a56-4812-a9a1-7e0c72aa03b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cs.CV</th>\n",
              "      <th>cs.LG</th>\n",
              "      <th>stat.ML</th>\n",
              "      <th>cs.AI</th>\n",
              "      <th>eess.IV</th>\n",
              "      <th>powerlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today deep convolutional neural networks (CNNs...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the paper, we propose a class of efficient ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The generative adversarial network (GAN) exhib...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though convolutional neural networks are widel...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In recent years, advances in the development o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c0a9b93-6a56-4812-a9a1-7e0c72aa03b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c0a9b93-6a56-4812-a9a1-7e0c72aa03b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c0a9b93-6a56-4812-a9a1-7e0c72aa03b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mlros.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dXTud62elxk6",
        "outputId": "b4337b5b-fb36-48e1-e198-f55ccc2bbdf8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  cs.CV  cs.LG  stat.ML  \\\n",
              "0  Today deep convolutional neural networks (CNNs...      0      1        0   \n",
              "1  In the paper, we propose a class of efficient ...      0      0        1   \n",
              "2  The generative adversarial network (GAN) exhib...      0      1        1   \n",
              "3  Though convolutional neural networks are widel...      1      1        0   \n",
              "4  In recent years, advances in the development o...      0      1        0   \n",
              "\n",
              "   cs.AI  eess.IV  powerlabel  \n",
              "0      0        0           8  \n",
              "1      0        1           5  \n",
              "2      1        0          14  \n",
              "3      0        0          24  \n",
              "4      0        0           8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a02232b-4bb1-4ce9-a518-c816821a415a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cs.CV</th>\n",
              "      <th>cs.LG</th>\n",
              "      <th>stat.ML</th>\n",
              "      <th>cs.AI</th>\n",
              "      <th>eess.IV</th>\n",
              "      <th>powerlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today deep convolutional neural networks (CNNs...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the paper, we propose a class of efficient ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The generative adversarial network (GAN) exhib...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though convolutional neural networks are widel...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In recent years, advances in the development o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a02232b-4bb1-4ce9-a518-c816821a415a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a02232b-4bb1-4ce9-a518-c816821a415a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a02232b-4bb1-4ce9-a518-c816821a415a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embeddings: BERT"
      ],
      "metadata": {
        "id": "7UJNt1-SCLKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings\n",
        "model = SentenceTransformer('multi-qa-distilbert-dot-v1')\n",
        "def bert_embeddings(col):\n",
        "  sentences = list(col)\n",
        "  sentence_embeddings = model.encode(sentences)\n",
        "  sentence_embeddings_df = pd.DataFrame(sentence_embeddings)\n",
        "  return sentence_embeddings_df"
      ],
      "metadata": {
        "id": "on8K6baGr_Ti"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mlros = bert_embeddings(train_mlros['text'])\n",
        "y_train_mlros = train_mlros[labels]"
      ],
      "metadata": {
        "id": "ErK1kvhuncl7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lpros = bert_embeddings(train_lpros['text'])\n",
        "y_train_lpros = train_lpros[labels]"
      ],
      "metadata": {
        "id": "KcGnZzCOqMg3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = bert_embeddings(train['text'])\n",
        "y_train = train[labels]"
      ],
      "metadata": {
        "id": "YSUOJgsFpN--"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = bert_embeddings(test['text'])\n",
        "y_test = test[labels]"
      ],
      "metadata": {
        "id": "J42I0ohSmz1G"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "- Binary Relevance\n",
        "- Classifier Chain\n",
        "- [Multilabel K-Nearest Neighbors](http://scikit.ml/api/skmultilearn.adapt.mlknn.html): \"uses k-NearestNeighbors find nearest examples to a test class and uses Bayesian inference to select assigned labels.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "KzCUFunEjbku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier Chain"
      ],
      "metadata": {
        "id": "MfssW72u3DEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cc_lr_fit(X_train, y_train, X_test):\n",
        "  # initialize classifier chains multi-label classifier\n",
        "  classifier = ClassifierChain(LogisticRegression())\n",
        "\n",
        "  # Training logistic regression model on train data\n",
        "  classifier.fit(X_train, y_train)\n",
        "\n",
        "  # predict\n",
        "  predictions = classifier.predict(X_test)\n",
        "  y_pred = pd.DataFrame.sparse.from_spmatrix(predictions)\n",
        "\n",
        "  return classifier, y_pred"
      ],
      "metadata": {
        "id": "gdpuufCD1V5W"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using classifier chain + naive bayes\n",
        "def cc_nb_fit(X_train, y_train, X_test):\n",
        "  # initialize classifier chains multi-label classifier\n",
        "  classifier = ClassifierChain(GaussianNB())\n",
        "\n",
        "  # Training logistic regression model on train data\n",
        "  classifier.fit(X_train, y_train)\n",
        "\n",
        "  # predict\n",
        "  predictions = classifier.predict(X_test)\n",
        "  y_pred = pd.DataFrame.sparse.from_spmatrix(predictions)\n",
        "\n",
        "  return classifier, y_pred"
      ],
      "metadata": {
        "id": "-C7YKhW81tkU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Relevance"
      ],
      "metadata": {
        "id": "XIly3aG63IPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using binary relevance\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def br_nb_fit(X_train, y_train, X_test):\n",
        "  # initialize classifier chains multi-label classifier\n",
        "  classifier = BinaryRelevance(GaussianNB())\n",
        "\n",
        "  # Training logistic regression model on train data\n",
        "  classifier.fit(X_train, y_train)\n",
        "\n",
        "  # predict\n",
        "  predictions = classifier.predict(X_test)\n",
        "  y_pred = pd.DataFrame.sparse.from_spmatrix(predictions)\n",
        "\n",
        "  return classifier, y_pred"
      ],
      "metadata": {
        "id": "FXHAAyFsrBvZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using binary relevance + logistic regression\n",
        "def br_lr_fit(X_train, y_train, X_test):\n",
        "  # initialize classifier chains multi-label classifier\n",
        "  classifier = BinaryRelevance(LogisticRegression())\n",
        "\n",
        "  # Training logistic regression model on train data\n",
        "  classifier.fit(X_train, y_train)\n",
        "\n",
        "  # predict\n",
        "  predictions = classifier.predict(X_test)\n",
        "  y_pred = pd.DataFrame.sparse.from_spmatrix(predictions)\n",
        "\n",
        "  return classifier, y_pred"
      ],
      "metadata": {
        "id": "HpisL_421mZg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "Pll7RIl93L6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "\n",
        "\n",
        "from skmultilearn.adapt import MLkNN\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def mlknn_fit(X_train, y_train, X_test, k, score):\n",
        "  \"\"\"\n",
        "  Returns:\n",
        "    classifier: a fitted KNN classifier\n",
        "    y_pred: predictions \n",
        "\n",
        "  Error:\n",
        "    for \"TypeError: __init__() takes 1 positional argument but 2 were given\", install the old version of sklearn\n",
        "    !pip uninstall scikit-learn -y\n",
        "    !pip install scikit-learn==0.24.1\n",
        "  \"\"\"\n",
        "  # initialize classifier chains multi-label classifier\n",
        "  classifier = MLkNN(k)\n",
        "\n",
        "  # Training logistic regression model on train data\n",
        "  classifier.fit(X_train, y_train)\n",
        "\n",
        "  # predict\n",
        "  predictions = classifier.predict(X_test)\n",
        "  y_pred = pd.DataFrame.sparse.from_spmatrix(predictions)\n",
        "\n",
        "  return classifier, y_pred"
      ],
      "metadata": {
        "id": "l9gz3fS_sz6W"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting"
      ],
      "metadata": {
        "id": "PdjFXhTX8dWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cc_lr_raw, y_pred_cc_lr_raw = cc_lr_fit(X_train, y_train, X_test)\n",
        "cc_nb_raw, y_pred_cc_nb_raw = cc_nb_fit(X_train, y_train, X_test)\n",
        "br_lr_raw, y_pred_br_lr_raw = br_lr_fit(X_train, y_train, X_test)\n",
        "br_nb_raw, y_pred_br_nb_raw = br_nb_fit(X_train, y_train, X_test)"
      ],
      "metadata": {
        "id": "-LlxqcZm2mMf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_lr_mlros, y_pred_cc_lr_mlros = cc_lr_fit(X_train_mlros, y_train_mlros, X_test)\n",
        "cc_nb_mlros, y_pred_cc_nb_mlros = cc_nb_fit(X_train_mlros, y_train_mlros, X_test)\n",
        "br_lr_mlros, y_pred_br_lr_mlros = br_lr_fit(X_train_mlros, y_train_mlros, X_test)\n",
        "br_nb_mlros, y_pred_br_nb_mlros = br_nb_fit(X_train_mlros, y_train_mlros, X_test)"
      ],
      "metadata": {
        "id": "EkfhUa1L2An2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_lr_lpros, y_pred_cc_lr_lpros = cc_lr_fit(X_train_lpros, y_train_lpros, X_test)\n",
        "cc_nb_lpros, y_pred_cc_nb_lpros = cc_nb_fit(X_train_lpros, y_train_lpros, X_test)\n",
        "br_lr_lpros, y_pred_br_lr_lpros = br_lr_fit(X_train_lpros, y_train_lpros, X_test)\n",
        "br_nb_lpros, y_pred_br_nb_lpros = br_nb_fit(X_train_lpros, y_train_lpros, X_test)"
      ],
      "metadata": {
        "id": "sCyE7mNr229S"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To use the mlknn package, the dataset should be converted to a sparse matrix.\n",
        "X_train_sparse = scipy.sparse.csr_matrix(X_train.values)\n",
        "y_train_sparse = scipy.sparse.csr_matrix(y_train.values)\n",
        "X_train_mlros_sparse = scipy.sparse.csr_matrix(X_train_mlros.values)\n",
        "y_train_mlros_sparse = scipy.sparse.csr_matrix(y_train_mlros.values)\n",
        "X_train_lpros_sparse = scipy.sparse.csr_matrix(X_train_lpros.values)\n",
        "y_train_lpros_sparse = scipy.sparse.csr_matrix(y_train_lpros.values)"
      ],
      "metadata": {
        "id": "VxI6f6L93SEB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = 'f1_macro'\n",
        "k = 5\n",
        "mlknn_raw, y_pred_mlknn_raw = mlknn_fit(X_train_sparse, y_train_sparse, X_test, k, score)\n",
        "mlknn_mlros, y_pred_mlknn_mlros = mlknn_fit(X_train_mlros_sparse, y_train_mlros_sparse, X_test, k, score)\n",
        "mlknn_lpros, y_pred_mlknn_lpros = mlknn_fit(X_train_lpros_sparse, y_train_lpros_sparse, X_test, k, score)"
      ],
      "metadata": {
        "id": "wxwIdIuNtFKl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Results \n",
        "- Evaluation metrics for classification problem\n",
        "  - Accuracy: number of correct predictions / total predictions. The accuracy could be misleading when the dataset is not balanced. For example, if there are four positives and one negative, the model that predicts all samples to be positive achieves 80% accuracy. \n",
        "  - Precision: true positives divided by the number of samples that were predicted to be positive. TP / (TP + FP)\n",
        "  - Recall: true positives divided by true positives + false negatives. TP / (TP + FN)\n",
        "  - The F1 score is the harmonic mean of the precision and recall. 2*(precision *  recall) / (precision + recall). \n",
        "  - Macro average: simple average of all classes. For example, if there are three classes, the macro average for precision is the average of precision of class A, precision of class B, and precision of class C.  \n",
        "  - Micro average: this is calculated by considering all true positives, false positives, and false negatives. For example, the micro average for precision is: sum of true positives (across three classes) / sum of true positives + sum of false positives \n",
        "  - Weighted average: average of the metric values weighted by the support of that class. For example: Precision of class A * Support of class A + Precision of class B * Support of class B / (Support of class A + Support of class B) \n",
        "  - [Hamming Loss](https://medium.datadriveninvestor.com/a-survey-of-evaluation-metrics-for-multilabel-classification-bb16e8cd41cd): computes the proportion of incorrectly predicted labels to the total number of labels. For a multilabel classification, we compute the number of False Positives and False Negative per instance and then average it over the total number of training instances. $\\frac{1}{|N|*|L|}\\sum_{i=1}^N \\sum_{j=1}^L xor(y_{i,j}, z_{i,j})$. Where N is the number of samples, L is the number of classes, $y_{ij}$ is the true label, $z_{ij}$ is the predicted label, and xor is the operator that returns zero if the prediction and the true label are the same. The optimal value for the hamming loss is zero.   \n",
        "\n"
      ],
      "metadata": {
        "id": "KV1Ii6Zo34SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def results(y_test, y_pred, labels, X_train, X_test):\n",
        "  print(classification_report(y_test, y_pred, target_names=labels))\n",
        "  print(\"Training Dataset Count\", X_train.shape[0])\n",
        "  print(\"Test Dataset Count\", X_test.shape[0])\n",
        "  print(\"Weighted Precision\", precision_score(y_test, y_pred, average='weighted'))\n",
        "  print(\"Weighted Recall\", recall_score(y_test, y_pred, average='weighted'))\n",
        "  print(\"Weighted F1\", f1_score(y_test, y_pred, average='weighted'))\n",
        "  print(\"Accuracy\", accuracy_score(y_test, y_pred))\n",
        "  print(\"Hamming Loss\", hamming_loss(y_test, y_pred))"
      ],
      "metadata": {
        "id": "eO6EzcCNpYb8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Raw data"
      ],
      "metadata": {
        "id": "w5qa0IPVAWfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for raw data (imbalanced data) \n",
        "results(y_test, y_pred_cc_lr_raw, labels, X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2yZadkUp40E",
        "outputId": "a7eeb444-ef4d-43f8-971f-2a4607f0b388"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.33      0.16      0.21       215\n",
            "       cs.LG       0.89      0.90      0.89       862\n",
            "     stat.ML       0.85      0.81      0.83       835\n",
            "       cs.AI       0.09      0.05      0.06        61\n",
            "     eess.IV       0.61      0.62      0.62       469\n",
            "\n",
            "   micro avg       0.78      0.73      0.75      2442\n",
            "   macro avg       0.55      0.51      0.52      2442\n",
            "weighted avg       0.75      0.73      0.74      2442\n",
            " samples avg       0.83      0.80      0.78      2442\n",
            "\n",
            "Training Dataset Count 3500\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7542915005405129\n",
            "Weighted Recall 0.7289107289107289\n",
            "Weighted F1 0.7385891999574948\n",
            "Accuracy 0.4806666666666667\n",
            "Hamming Loss 0.15453333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_cc_nb_raw, labels, X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBCUjkPb20RH",
        "outputId": "9281a6c3-e42d-41c4-a669-93e32ecda9e2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.32      0.48      0.39       215\n",
            "       cs.LG       0.90      0.89      0.90       862\n",
            "     stat.ML       0.91      0.79      0.84       835\n",
            "       cs.AI       0.07      0.49      0.13        61\n",
            "     eess.IV       0.59      0.80      0.68       469\n",
            "\n",
            "   micro avg       0.66      0.79      0.72      2442\n",
            "   macro avg       0.56      0.69      0.59      2442\n",
            "weighted avg       0.77      0.79      0.77      2442\n",
            " samples avg       0.69      0.84      0.72      2442\n",
            "\n",
            "Training Dataset Count 3500\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7734314692280188\n",
            "Weighted Recall 0.7927927927927928\n",
            "Weighted F1 0.7733896587372856\n",
            "Accuracy 0.31066666666666665\n",
            "Hamming Loss 0.2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_br_lr_raw, labels, X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr1yYPE821s4",
        "outputId": "e11a6138-9075-4d36-f82c-33d5d0417c1c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.33      0.16      0.21       215\n",
            "       cs.LG       0.89      0.90      0.90       862\n",
            "     stat.ML       0.84      0.84      0.84       835\n",
            "       cs.AI       0.03      0.02      0.02        61\n",
            "     eess.IV       0.62      0.58      0.59       469\n",
            "\n",
            "   micro avg       0.78      0.73      0.75      2442\n",
            "   macro avg       0.54      0.50      0.51      2442\n",
            "weighted avg       0.75      0.73      0.74      2442\n",
            " samples avg       0.82      0.80      0.77      2442\n",
            "\n",
            "Training Dataset Count 3500\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7484836382551212\n",
            "Weighted Recall 0.730958230958231\n",
            "Weighted F1 0.7368768895657534\n",
            "Accuracy 0.4553333333333333\n",
            "Hamming Loss 0.15506666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_br_nb_raw, labels, X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCP7nEv_2w3M",
        "outputId": "bcd49a44-62d6-4d3c-b46e-546b3c1427ab"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.32      0.48      0.39       215\n",
            "       cs.LG       0.91      0.90      0.90       862\n",
            "     stat.ML       0.90      0.81      0.85       835\n",
            "       cs.AI       0.07      0.46      0.13        61\n",
            "     eess.IV       0.61      0.80      0.70       469\n",
            "\n",
            "   micro avg       0.67      0.80      0.73      2442\n",
            "   macro avg       0.56      0.69      0.59      2442\n",
            "weighted avg       0.78      0.80      0.78      2442\n",
            " samples avg       0.71      0.85      0.74      2442\n",
            "\n",
            "Training Dataset Count 3500\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7759783676204339\n",
            "Weighted Recall 0.800982800982801\n",
            "Weighted F1 0.7802777062670232\n",
            "Accuracy 0.33\n",
            "Hamming Loss 0.1928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_mlknn_raw, labels, X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL0Ot9U36Wyp",
        "outputId": "0a8888ad-1d86-46a3-c39f-476b78cc2cc9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.42      0.27      0.33       215\n",
            "       cs.LG       0.87      0.92      0.90       862\n",
            "     stat.ML       0.86      0.81      0.84       835\n",
            "       cs.AI       0.40      0.03      0.06        61\n",
            "     eess.IV       0.65      0.53      0.58       469\n",
            "\n",
            "   micro avg       0.80      0.73      0.76      2442\n",
            "   macro avg       0.64      0.51      0.54      2442\n",
            "weighted avg       0.77      0.73      0.74      2442\n",
            " samples avg       0.84      0.80      0.79      2442\n",
            "\n",
            "Training Dataset Count 3500\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7737869984320097\n",
            "Weighted Recall 0.7293202293202293\n",
            "Weighted F1 0.744596570015297\n",
            "Accuracy 0.49666666666666665\n",
            "Hamming Loss 0.1472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MLROS"
      ],
      "metadata": {
        "id": "PwCZzxFBAfTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_cc_lr_mlros, labels, X_train_mlros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs57s9PSoySZ",
        "outputId": "92208416-f11d-4375-84ac-3db92873328b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.32      0.16      0.22       215\n",
            "       cs.LG       0.88      0.91      0.90       862\n",
            "     stat.ML       0.83      0.81      0.82       835\n",
            "       cs.AI       0.07      0.10      0.08        61\n",
            "     eess.IV       0.61      0.59      0.60       469\n",
            "\n",
            "   micro avg       0.76      0.73      0.74      2442\n",
            "   macro avg       0.54      0.51      0.52      2442\n",
            "weighted avg       0.74      0.73      0.73      2442\n",
            " samples avg       0.81      0.80      0.77      2442\n",
            "\n",
            "Training Dataset Count 3928\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7434889262727635\n",
            "Weighted Recall 0.7289107289107289\n",
            "Weighted F1 0.7336679690523359\n",
            "Accuracy 0.45666666666666667\n",
            "Hamming Loss 0.16386666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_cc_nb_mlros, labels, X_train_mlros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ebkN_iw2iKd",
        "outputId": "a02350e7-4c02-4681-d63d-f5cdfc1699d8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.32      0.50      0.39       215\n",
            "       cs.LG       0.90      0.89      0.90       862\n",
            "     stat.ML       0.90      0.81      0.85       835\n",
            "       cs.AI       0.07      0.52      0.13        61\n",
            "     eess.IV       0.59      0.81      0.68       469\n",
            "\n",
            "   micro avg       0.65      0.80      0.72      2442\n",
            "   macro avg       0.56      0.71      0.59      2442\n",
            "weighted avg       0.77      0.80      0.78      2442\n",
            " samples avg       0.69      0.85      0.73      2442\n",
            "\n",
            "Training Dataset Count 3928\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7689531116042975\n",
            "Weighted Recall 0.8046683046683046\n",
            "Weighted F1 0.7765447188089878\n",
            "Accuracy 0.30666666666666664\n",
            "Hamming Loss 0.2044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_br_lr_mlros, labels, X_train_mlros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLKlUOeV2kXI",
        "outputId": "46b0d237-c01c-4ee1-cf88-61f608f39ae6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.32      0.16      0.22       215\n",
            "       cs.LG       0.88      0.91      0.89       862\n",
            "     stat.ML       0.82      0.84      0.83       835\n",
            "       cs.AI       0.09      0.11      0.10        61\n",
            "     eess.IV       0.61      0.56      0.59       469\n",
            "\n",
            "   micro avg       0.76      0.73      0.75      2442\n",
            "   macro avg       0.55      0.52      0.53      2442\n",
            "weighted avg       0.74      0.73      0.73      2442\n",
            " samples avg       0.81      0.80      0.77      2442\n",
            "\n",
            "Training Dataset Count 3928\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7414861992856538\n",
            "Weighted Recall 0.7334152334152334\n",
            "Weighted F1 0.7347231144331895\n",
            "Accuracy 0.436\n",
            "Hamming Loss 0.16253333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_br_nb_mlros, labels, X_train_mlros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeR1IBZ_2bGD",
        "outputId": "139af51f-5069-4142-955b-db91d8db23d8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.32      0.50      0.39       215\n",
            "       cs.LG       0.90      0.89      0.90       862\n",
            "     stat.ML       0.89      0.83      0.86       835\n",
            "       cs.AI       0.07      0.48      0.13        61\n",
            "     eess.IV       0.61      0.81      0.69       469\n",
            "\n",
            "   micro avg       0.66      0.81      0.73      2442\n",
            "   macro avg       0.56      0.70      0.59      2442\n",
            "weighted avg       0.77      0.81      0.78      2442\n",
            " samples avg       0.70      0.85      0.73      2442\n",
            "\n",
            "Training Dataset Count 3928\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.7689804385625978\n",
            "Weighted Recall 0.8087633087633087\n",
            "Weighted F1 0.7802324974953598\n",
            "Accuracy 0.31733333333333336\n",
            "Hamming Loss 0.1972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_mlknn_mlros, labels, X_train_mlros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMLkIaxMg2q9",
        "outputId": "b4277877-3710-428d-b73a-c5ce87921859"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.42      0.27      0.33       215\n",
            "       cs.LG       0.86      0.90      0.88       862\n",
            "     stat.ML       0.80      0.81      0.81       835\n",
            "       cs.AI       0.06      0.07      0.06        61\n",
            "     eess.IV       0.64      0.51      0.57       469\n",
            "\n",
            "   micro avg       0.75      0.72      0.74      2442\n",
            "   macro avg       0.56      0.51      0.53      2442\n",
            "weighted avg       0.74      0.72      0.73      2442\n",
            " samples avg       0.81      0.78      0.76      2442\n",
            "\n",
            "Training Dataset Count 3928\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.740256144500976\n",
            "Weighted Recall 0.7211302211302212\n",
            "Weighted F1 0.7277281648046727\n",
            "Accuracy 0.45\n",
            "Hamming Loss 0.16706666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LPROS"
      ],
      "metadata": {
        "id": "gpbMXHlXAn7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_cc_lr_lpros, labels, X_train_lpros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weEOOcSFrl1K",
        "outputId": "e0813d4f-944c-4d25-8b29-1b071679c3f2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.20      0.34      0.25       215\n",
            "       cs.LG       0.85      0.89      0.87       862\n",
            "     stat.ML       0.73      0.85      0.78       835\n",
            "       cs.AI       0.07      0.15      0.09        61\n",
            "     eess.IV       0.54      0.53      0.53       469\n",
            "\n",
            "   micro avg       0.64      0.74      0.69      2442\n",
            "   macro avg       0.48      0.55      0.51      2442\n",
            "weighted avg       0.67      0.74      0.70      2442\n",
            " samples avg       0.69      0.80      0.69      2442\n",
            "\n",
            "Training Dataset Count 29414\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.6704410997894021\n",
            "Weighted Recall 0.7416052416052417\n",
            "Weighted F1 0.7022379011511257\n",
            "Accuracy 0.2846666666666667\n",
            "Hamming Loss 0.222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_cc_nb_lpros, labels, X_train_lpros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ClhYcxD3H8r",
        "outputId": "8c8d0aef-9b94-4a3f-873e-35b1ce09352c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.23      0.50      0.31       215\n",
            "       cs.LG       0.80      0.90      0.85       862\n",
            "     stat.ML       0.59      0.95      0.73       835\n",
            "       cs.AI       0.03      0.03      0.03        61\n",
            "     eess.IV       0.56      0.30      0.40       469\n",
            "\n",
            "   micro avg       0.59      0.75      0.66      2442\n",
            "   macro avg       0.44      0.54      0.46      2442\n",
            "weighted avg       0.61      0.75      0.65      2442\n",
            " samples avg       0.63      0.80      0.66      2442\n",
            "\n",
            "Training Dataset Count 29414\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.6146828165760954\n",
            "Weighted Recall 0.7452907452907452\n",
            "Weighted F1 0.652862025088922\n",
            "Accuracy 0.14666666666666667\n",
            "Hamming Loss 0.25453333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_br_lr_lpros, labels, X_train_lpros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6z7JF23ITU",
        "outputId": "355f4ed9-1495-45d7-8bfa-fd0dfd884552"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.20      0.34      0.25       215\n",
            "       cs.LG       0.85      0.89      0.87       862\n",
            "     stat.ML       0.73      0.87      0.80       835\n",
            "       cs.AI       0.08      0.20      0.12        61\n",
            "     eess.IV       0.54      0.53      0.53       469\n",
            "\n",
            "   micro avg       0.64      0.75      0.69      2442\n",
            "   macro avg       0.48      0.57      0.51      2442\n",
            "weighted avg       0.67      0.75      0.71      2442\n",
            " samples avg       0.69      0.80      0.69      2442\n",
            "\n",
            "Training Dataset Count 29414\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.673032126632292\n",
            "Weighted Recall 0.7477477477477478\n",
            "Weighted F1 0.7061137954974611\n",
            "Accuracy 0.2693333333333333\n",
            "Hamming Loss 0.22106666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_br_nb_lpros, labels, X_train_lpros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xZOWUq93ExO",
        "outputId": "a357862e-7d21-4350-aece-00b99bf07571"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.23      0.50      0.31       215\n",
            "       cs.LG       0.80      0.90      0.85       862\n",
            "     stat.ML       0.59      0.95      0.73       835\n",
            "       cs.AI       0.01      0.02      0.02        61\n",
            "     eess.IV       0.57      0.30      0.40       469\n",
            "\n",
            "   micro avg       0.58      0.74      0.66      2442\n",
            "   macro avg       0.44      0.53      0.46      2442\n",
            "weighted avg       0.61      0.74      0.65      2442\n",
            " samples avg       0.62      0.80      0.65      2442\n",
            "\n",
            "Training Dataset Count 29414\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.6131598303652921\n",
            "Weighted Recall 0.7448812448812449\n",
            "Weighted F1 0.6514233094167725\n",
            "Accuracy 0.142\n",
            "Hamming Loss 0.2554666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results(y_test, y_pred_mlknn_lpros, labels, X_train_lpros, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEKL5Hi1-ouL",
        "outputId": "73da95f0-919d-424a-fddf-37e5453bd39b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cs.CV       0.31      0.32      0.31       215\n",
            "       cs.LG       0.86      0.81      0.84       862\n",
            "     stat.ML       0.76      0.81      0.79       835\n",
            "       cs.AI       0.06      0.07      0.06        61\n",
            "     eess.IV       0.51      0.54      0.52       469\n",
            "\n",
            "   micro avg       0.68      0.70      0.69      2442\n",
            "   macro avg       0.50      0.51      0.50      2442\n",
            "weighted avg       0.69      0.70      0.69      2442\n",
            " samples avg       0.73      0.75      0.70      2442\n",
            "\n",
            "Training Dataset Count 29414\n",
            "Test Dataset Count 1500\n",
            "Weighted Precision 0.6894622981728942\n",
            "Weighted Recall 0.6994266994266994\n",
            "Weighted F1 0.6937668986247858\n",
            "Accuracy 0.36\n",
            "Hamming Loss 0.2032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "In terms of hamming loss, the mlknn algorithm combined with the raw data performs the best. However, it can't predict a minor label (cs.AI) at all. The classifier chain of logistic regressions can be an alternative."
      ],
      "metadata": {
        "id": "WQ76qH-N1pmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix: Deep Learning\n",
        "* Use deep learning to improve the accuracy of the model.\n",
        "* Resource: https://keras.io/examples/nlp/multi_label_classification/"
      ],
      "metadata": {
        "id": "f4LKMJ46ZP1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove entries of which term occurs once \n",
        "df['terms_tuple'] = df['terms'].map(tuple)\n",
        "df_filtered_2 = df.groupby(\"terms_tuple\").filter(lambda x: len(x) > 1)\n",
        "df_filtered_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kPixzZflT4F",
        "outputId": "9d6b4aa6-52c3-470b-ecdf-404a38fbe895"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4475, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered_2[\"terms\"] = df_filtered_2[\"terms\"].apply(lambda x: literal_eval(str(x)))\n",
        "df_filtered_2[\"terms\"].values[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EeYi2PUn4Yn",
        "outputId": "4f3091bd-6db2-4c46-c871-029c1d8c1076"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['cs.CV']), list(['cs.CV', 'cs.AI']),\n",
              "       list(['cs.CV', 'cs.LG']), list(['stat.ML', 'cs.LG']),\n",
              "       list(['cs.LG'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial train and test split.\n",
        "train_2, test_2 = train_test_split(df_filtered_2, test_size=0.3, stratify=df_filtered_2[\"terms\"].values, random_state=1)\n",
        "\n",
        "# Splitting the test set further into validation\n",
        "val_2 = test_2.sample(frac=0.5, random_state = 1)\n",
        "test_2.drop(val_2.index, inplace=True)"
      ],
      "metadata": {
        "id": "PP6cti4dd_fK"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_2[\"summaries\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZZ0o8HjWlfC",
        "outputId": "d089c851-6ca1-4705-8702-f469965bcbb3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3132.000000\n",
              "mean      156.329183\n",
              "std        41.462784\n",
              "min        24.000000\n",
              "25%       127.000000\n",
              "50%       154.000000\n",
              "75%       183.000000\n",
              "max       279.000000\n",
              "Name: summaries, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = tf.ragged.constant(train_2[\"terms\"].values)\n",
        "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
        "lookup.adapt(terms)\n",
        "vocab = lookup.get_vocabulary()\n",
        "\n",
        "def invert_multi_hot(encoded_labels):\n",
        "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
        "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
        "    return np.take(vocab, hot_indices)\n",
        "\n",
        "print(\"Vocabulary:\\n\")\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTCwXbekYT1R",
        "outputId": "0ba9364e-e7f6-4786-e2a6-b9174786c683"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "\n",
            "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.CR', 'cs.SI', 'math.OC', 'eess.SP', 'cs.GR', 'cs.MM', 'cs.SY', 'cs.IR', 'eess.SY', 'cs.MA', 'cs.DC', 'stat.AP', 'math.IT', 'cs.IT', 'stat.TH', 'math.ST', 'cs.HC', 'cs.GT', 'stat.ME', 'eess.AS', 'cs.SD', 'q-bio.QM', 'stat.CO', 'math.NA', 'cs.NA', 'cs.DS', 'cs.CY', 'astro-ph.IM', 'q-bio.NC', 'cs.PL', 'physics.comp-ph', 'cs.DB', 'physics.med-ph', 'physics.chem-ph', 'math.PR', 'cs.SE', 'cs.NI', 'cs.CG', 'I.4.8', 'I.2.6', 'I.2.10', 'q-fin.CP', 'physics.data-an', 'math.DS', 'cond-mat.stat-mech', 'I.4', '68T07']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seqlen = 150\n",
        "batch_size = 128\n",
        "padding_token = \"<pad>\"\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "def make_dataset(dataframe, is_train=True):\n",
        "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
        "    label_binarized = lookup(labels).numpy()\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dataframe[\"summaries\"].values, label_binarized))\n",
        "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "jKMeKKkbXCIU"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = make_dataset(train_2, is_train=True)\n",
        "validation_dataset = make_dataset(val_2, is_train=False)\n",
        "test_dataset = make_dataset(test_2, is_train=False)"
      ],
      "metadata": {
        "id": "_bbzKixUXsHr"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "gfMVzI_aecbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c15e99a-38ff-48ac-c345-f620298930ed"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 56), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "for i, text in enumerate(text_batch[:5]):\n",
        "    label = label_batch[i].numpy()[None, ...]\n",
        "    print(f\"Abstract: {text}\")\n",
        "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
        "    print(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ap_qliBmXSy",
        "outputId": "93aad629-5977-41db-f05a-f9f6bf263524"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract: b'Learning meaningful representations of data is an important aspect of machine\\nlearning and has recently been successfully applied to many domains like\\nlanguage understanding or computer vision. Instead of training a model for one\\nspecific task, representation learning is about training a model to capture all\\nuseful information in the underlying data and make it accessible for a\\npredictor. For predictive process analytics, it is essential to have all\\nexplanatory characteristics of a process instance available when making\\npredictions about the future, as well as for clustering and anomaly detection.\\nDue to the large variety of perspectives and types within business process\\ndata, generating a good representation is a challenging task. In this paper, we\\npropose a novel approach for representation learning of business process\\ninstances which can process and combine most perspectives in an event log. In\\nconjunction with a self-supervised pre-training method, we show the\\ncapabilities of the approach through a visualization of the representation\\nspace and case retrieval. Furthermore, the pre-trained model is fine-tuned to\\nmultiple process prediction tasks and demonstrates its effectiveness in\\ncomparison with existing approaches.'\n",
            "Label(s): ['cs.LG' 'stat.ML' 'cs.AI']\n",
            " \n",
            "Abstract: b'In the era of autonomous driving, urban mapping represents a core step to let\\nvehicles interact with the urban context. Successful mapping algorithms have\\nbeen proposed in the last decade building the map leveraging on data from a\\nsingle sensor. The focus of the system presented in this paper is twofold: the\\njoint estimation of a 3D map from lidar data and images, based on a 3D mesh,\\nand its texturing. Indeed, even if most surveying vehicles for mapping are\\nendowed by cameras and lidar, existing mapping algorithms usually rely on\\neither images or lidar data; moreover both image-based and lidar-based systems\\noften represent the map as a point cloud, while a continuous textured mesh\\nrepresentation would be useful for visualization and navigation purposes. In\\nthe proposed framework, we join the accuracy of the 3D lidar data, and the\\ndense information and appearance carried by the images, in estimating a\\nvisibility consistent map upon the lidar measurements, and refining it\\nphotometrically through the acquired images. We evaluate the proposed framework\\nagainst the KITTI dataset and we show the performance improvement with respect\\nto two state of the art urban mapping algorithms, and two widely used surface\\nreconstruction algorithms in Computer Graphics.'\n",
            "Label(s): ['cs.CV']\n",
            " \n",
            "Abstract: b'Image segmentation is still an open problem especially when intensities of\\nthe interested objects are overlapped due to the presence of intensity\\ninhomogeneity (also known as bias field). To segment images with intensity\\ninhomogeneities, a bias correction embedded level set model is proposed where\\nInhomogeneities are Estimated by Orthogonal Primary Functions (IEOPF). In the\\nproposed model, the smoothly varying bias is estimated by a linear combination\\nof a given set of orthogonal primary functions. An inhomogeneous intensity\\nclustering energy is then defined and membership functions of the clusters\\ndescribed by the level set function are introduced to rewrite the energy as a\\ndata term of the proposed model. Similar to popular level set methods, a\\nregularization term and an arc length term are also included to regularize and\\nsmooth the level set function, respectively. The proposed model is then\\nextended to multichannel and multiphase patterns to segment colourful images\\nand images with multiple objects, respectively. It has been extensively tested\\non both synthetic and real images that are widely used in the literature and\\npublic BrainWeb and IBSR datasets. Experimental results and comparison with\\nstate-of-the-art methods demonstrate that advantages of the proposed model in\\nterms of bias correction and segmentation accuracy.'\n",
            "Label(s): ['cs.CV']\n",
            " \n",
            "Abstract: b'Medical imaging AI systems such as disease classification and segmentation\\nare increasingly inspired and transformed from computer vision based AI\\nsystems. Although an array of adversarial training and/or loss function based\\ndefense techniques have been developed and proved to be effective in computer\\nvision, defending against adversarial attacks on medical images remains largely\\nan uncharted territory due to the following unique challenges: 1) label\\nscarcity in medical images significantly limits adversarial generalizability of\\nthe AI system; 2) vastly similar and dominant fore- and background in medical\\nimages make it hard samples for learning the discriminating features between\\ndifferent disease classes; and 3) crafted adversarial noises added to the\\nentire medical image as opposed to the focused organ target can make clean and\\nadversarial examples more discriminate than that between different disease\\nclasses. In this paper, we propose a novel robust medical imaging AI framework\\nbased on Semi-Supervised Adversarial Training (SSAT) and Unsupervised\\nAdversarial Detection (UAD), followed by designing a new measure for assessing\\nsystems adversarial risk. We systematically demonstrate the advantages of our\\nrobust medical imaging AI system over the existing adversarial defense\\ntechniques under diverse real-world settings of adversarial attacks using a\\nbenchmark OCT imaging data set.'\n",
            "Label(s): ['cs.CV' 'cs.LG' 'eess.IV']\n",
            " \n",
            "Abstract: b'Deep-learning-based image processing has emerged as a valuable tool in recent\\nyears owing to its high performance. However, the quality of\\ndeep-learning-based methods relies heavily on the amount of training data, and\\nthe cost of acquiring a large amount of data is often prohibitive in medical\\nfields. Therefore, we performed CT modality conversion based on deep learning\\nrequiring only a small number of unsupervised images. The proposed method is\\nbased on generative adversarial networks (GANs) with several extensions\\ntailored for CT images. This method emphasizes the preservation of the\\nstructure in the processed images and reduction in the amount of training data.\\nThis method was applied to realize the conversion of mega-voltage computed\\ntomography (MVCT) to kilo-voltage computed tomography (kVCT) images. Training\\nwas performed using several datasets acquired from patients with head and neck\\ncancer. The size of the datasets ranged from 16 slices (for two patients) to\\n2745 slices (for 137 patients) of MVCT and 2824 slices of kVCT for 98 patients.\\nThe quality of the processed MVCT images was considerably enhanced, and the\\nstructural changes in the images were minimized. With an increase in the size\\nof training data, the image quality exhibited a satisfactory convergence from a\\nfew hundred slices. In addition to statistical and visual evaluations, these\\nresults were clinically evaluated by medical doctors in terms of the accuracy\\nof contouring. We developed an MVCT to kVCT conversion model based on deep\\nlearning, which can be trained using a few hundred unpaired images. The\\nstability of the model against the change in the data size was demonstrated.\\nThis research promotes the reliable use of deep learning in clinical medicine\\nby partially answering the commonly asked questions: \"Is our data enough? How\\nmuch data must we prepare?\"'\n",
            "Label(s): ['cs.CV' 'physics.med-ph']\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "train_2[\"summaries\"].str.lower().str.split().apply(vocabulary.update)\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J33zbLSm5mc",
        "outputId": "3618de1f-7cb3-4b41-ad57-528a578cc207"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = layers.TextVectorization(max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\")\n",
        "\n",
        "with tf.device(\"/CPU:0\"):\n",
        "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "test_dataset = test_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)"
      ],
      "metadata": {
        "id": "3GoqN3i0mzlg"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "    shallow_mlp_model = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(256, activation=\"relu\"),\n",
        "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
        "        ]  \n",
        "    )\n",
        "    return shallow_mlp_model"
      ],
      "metadata": {
        "id": "hvT6Bfv2osvr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "shallow_mlp_model = make_model()\n",
        "shallow_mlp_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\"]\n",
        ")\n",
        "\n",
        "history = shallow_mlp_model.fit(\n",
        "    train_dataset, validation_data=validation_dataset, epochs=epochs\n",
        ")\n",
        "\n",
        "\n",
        "def plot_result(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_result(\"loss\")\n",
        "plot_result(\"categorical_accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bp83Ez6Sov4e",
        "outputId": "15ac14ff-c139-415d-adbc-6eee2f2bdb38"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.1604 - categorical_accuracy: 0.7759 - val_loss: 0.0628 - val_categorical_accuracy: 0.8690\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0234 - categorical_accuracy: 0.9275 - val_loss: 0.0575 - val_categorical_accuracy: 0.8795\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 0.0058 - categorical_accuracy: 0.9026 - val_loss: 0.0683 - val_categorical_accuracy: 0.8690\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.0017 - categorical_accuracy: 0.9205 - val_loss: 0.0724 - val_categorical_accuracy: 0.8824\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 7.6626e-04 - categorical_accuracy: 0.9224 - val_loss: 0.0800 - val_categorical_accuracy: 0.8720\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 4.3503e-04 - categorical_accuracy: 0.9205 - val_loss: 0.0852 - val_categorical_accuracy: 0.8631\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.8098e-04 - categorical_accuracy: 0.9231 - val_loss: 0.0878 - val_categorical_accuracy: 0.8720\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.9318e-04 - categorical_accuracy: 0.9186 - val_loss: 0.0918 - val_categorical_accuracy: 0.8705\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.3790e-04 - categorical_accuracy: 0.9195 - val_loss: 0.0966 - val_categorical_accuracy: 0.8661\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.9538e-05 - categorical_accuracy: 0.9173 - val_loss: 0.0986 - val_categorical_accuracy: 0.8676\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 7.3621e-05 - categorical_accuracy: 0.9266 - val_loss: 0.1021 - val_categorical_accuracy: 0.8631\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.6583e-05 - categorical_accuracy: 0.9253 - val_loss: 0.1062 - val_categorical_accuracy: 0.8661\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.4100e-05 - categorical_accuracy: 0.9282 - val_loss: 0.1080 - val_categorical_accuracy: 0.8661\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 3.4922e-05 - categorical_accuracy: 0.9310 - val_loss: 0.1103 - val_categorical_accuracy: 0.8646\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 2.8513e-05 - categorical_accuracy: 0.9298 - val_loss: 0.1131 - val_categorical_accuracy: 0.8646\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 2.3356e-05 - categorical_accuracy: 0.9310 - val_loss: 0.1155 - val_categorical_accuracy: 0.8646\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 1.9489e-05 - categorical_accuracy: 0.9272 - val_loss: 0.1173 - val_categorical_accuracy: 0.8676\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 1.6380e-05 - categorical_accuracy: 0.9301 - val_loss: 0.1191 - val_categorical_accuracy: 0.8661\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3772e-05 - categorical_accuracy: 0.9278 - val_loss: 0.1217 - val_categorical_accuracy: 0.8601\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.1811e-05 - categorical_accuracy: 0.9227 - val_loss: 0.1231 - val_categorical_accuracy: 0.8646\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEXCAYAAAC3c9OwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5dn48e+dbQIkhC0JS5RFFmVRWUStoqCiaLVURcG6oLXl1RartfqW1tZS39ra2trW6q+ttWpdKu6WVhQXSF2qlkX2zYCIYd9JgJBl7t8fzwkchkkyyeRkJuH+XNdcc5bnnHPPmeWe5yzPI6qKMcYYEykl0QEYY4xJTpYgjDHGRGUJwhhjTFSWIIwxxkRlCcIYY0xUliCMMcZEZQmimRGRJ0TkX4mOoyYiskREpga8jZEioiLSKdp4DcuME5G4r+mOZVuNQUSuF5HSILdhGk5E1orIHYmOI2iWIALi/YjU9niigau+FbimEUNtMiJyu4jsEZHWUealish6Efl5A1b9H6ALsD3uIA+PKdqPQCDbSkYi0k1EHhGRYhEp996fv4hIQQJjmlrD92lTomJqySxBBKeL7/HNKNNu9RcWkfRYVqqqu1V1VyPG2ZSeAkLAFVHmXYjbL3+t70pVtVxVN2kT3PXZlNtKJBHpCcwFBgITgd64PyYDgDki0iPg7WfUMnslh3+XugCDgoznaGUJIiDej8gmVd0E7PJPAzKBXSJylYjMEpH9wP+ISEcRedb7x7ZfRJaKyA3+9UYeYhKRQhH5fyLycxHZJiJbROTXIlLjexvjdupcr4jkicg/vHV8LiJfr2OfbAWmA9HK3QgUqupqr6axSET2ev9aHxWRdrW8niMO+4jIdV5M+7z9lR+xzHFe7Ju87cwXkYv9rx/oDtxf/S+1lm1dJiKLReSAiHwhIneJiPjmrxWRH4nIn70aVLGI3Fnbvqrhdf6PiBR5/+aLROSbUeavEpEy7z2bKSJp3rxBIvKOt/1SEVkoIqNq2dzDQBg4T1XfUdV1qjobOM+b/rC33kkisllEUiNi+buITPeNXyIi87zYPhORe/1JwNtHU0XkMRHZBTxTS2yV/u+X99gaZV1Pe691k0TUBEXkWBF5RURKvMfLElEzEpGLRORj7/O9XUT+KSKZviKZtb2ntb0fzYaq2iPgBzDO7eqD4z0ABdZ683oCBUA34E7gZKAXMAkoB871LfsE8C/feCGwG7gH6AtcCVQCV9USTyzbqXO9wAxgKXAGMNhbphSYWsu2x+B+YHr7puUDFcDV3vhtwDnefjobWAQ85Ss/0tt/nWoYP9Xbxl1e7P+DOyTkfw9OAm7C/fPs7ZUtB4735ncAvgB+CnQGOtewraFAlVeuL3C1tw9u8W1rrbf9yd62bvHWcXot++l6oNQ3fqm3jyZ727nFG7/Emz/Me3+uxiW2k4DvAmne/MXA08DxXgyX1rR977WHgR/WMP8ub35771EGjPHNzwL2Ald64xcAe4AbgOOAUbhawK8j9tEe4H+9+PrUsO2pwJI6vm/V6/K//+XAZd78FOAT3OHCYd7jI1yNSXyf00rgZ0B/4ETgDqB1LO9pXe9Hc3kkPICj4UHNCeJ7MSw7DXjUN/4ERyaIDyOWecu/TIwxRm6n1vV6XzwFzvDN7477sZxay3ZSgM+Bn/um3QnsBDJrWGYMcABI8cZHUnuC+DvwVsQ6HvW/BzVs5yPgR77xtcAdEWUit/UMMCuizFSgOGI9z0aU+dS/rSixXM/hCeID4LGIMk8A73vDl+ESenYN69sDTIzxs3Cq9xovrWH+pd784d74yxyewK/xYsn0xt8Ffhyxjq/iEmn1D/Ja4J8xxDbV+4yVRjye9ZVZW8P7X72vRnvr6OGb34tDNabq/T2tljhqfU/rej+ay8MOMSXWXP+IuBO1d3mHV7aLu4rlMuDYOtazKGJ8A5BXU+F6bKe29Z6A+0L9t3qmqn7ulamRqoaBx4HrfIclvg48o6plXnzniMhbXrW9BPcDlIH7Jx+LE4API6YdNi4ibUTkVyKyTER2evtgGHXv62jb+iBi2vtANxFp65tWr/eoHtvp7w2/hUu8n4nIMyIyUUSyfWUfAB4Vd0jzLhE5vh7brsvTwFfl0MUHVwMvVb+fuFrWXd7hnlJvX/8daMPh7+lh34darMbVfv2P70aUifb+V++rE4ANqrq2eqaqrsG9J9VlBgPv1BFHbe9pXe9Hs2AJIrH2RozfAXwPuB84F/fBfxX341ibiohxpfb3NtbtxLLehpysfRx3YvECEfkS7rDHowAi0h14DViOO5k9lEPnLOraD/Xxa2/9P8YdxjoZl+wacxv+fVPf96he21DVEmAI7lDgOuAHwAoR6erNn4r78XsV+BKwSGo+Z1Tkrbd/DfP7e/OLvPHXcIdTxopIHu48xdO+8im4Q3D+H/QTgT7AVl+5yO9DTcpVtSji0VhXMdXn81zje1rX+9FcWIJILmfiqtlPqeoC3D+lvkm6nRW4z8/w6gkicixQ5xfAq2m8jTsxfSMwz4sD3L/4DOC7qvqhqq6KZZ0RlgOnRUyLHD8TeFJVX1LVRUAx7vi4XzmQSu2W487BRK672PuRaCw1bWdZ9YiqVqrqLFX9Ae4HuA1wsW/+p6r6oKp+GXe12DeibUhVtwMzgW9JxCXJ3vi3gddVdYdX/gDwAq7mMB7YhDtEWW0+7txO5I96kapW1ndHxCja+7/cG14OdBXflVgi0gv3Oaven5/g/jw1WF3vR3PQvM6ot3yrgPEiciawDXfiqyfuw5pU21HVlSLyBvBnEZkE7Mcdxtgf4yr+ivuXWY47B1HtU1ziuU1EXsZ9sW+LNS7Pg8B/ROQHwIu48waXRpRZBVwqIv/A/RP8Ce7qMr+1wAgReRo4oKrbomzrN7jLPqfiDpucgqud/bCeMdflfuAFEZkHvIk7L3M17tAg4q7AOg53vH8H7kRwNrBcRFrhakwveK8pH5dcPq5le5NxJ3HfFpEf4d6X44B7AfHm+z2NOyTTE3dsPuybdw/wLxH5HHgeV9sYiDuH8b/13RFAmogccbgxohZxWsT7fx1uf4H7c7IIeEZEqi83/wMukc3yxu8F/ikiRbj3VYDzgT+r6r66Aqzt/Yj9ZSae1SCSy89whzlex32w9lL75X6J3s71wGe4L9U/cV+ktTEu+yruJF6KtxwA3r/5W4Hbcf/mvoE7JBYzVf0IVzO5GfdDcBnu5Kbf7cAW4D3cfvjIG/a7GzgGV8PaShSqOh93qOpyYAlwn/d4qD4x10VVX8Ul8u/i9sutwLdU9Z9ekV24E79v42p3dwDfUNX3cCdk2+NOaq8EXsEdk7+9lu2txtXmluLuX1mDe5+WA6eo6mcRi7wHrMcdfvIfXkJVZwJfxv1I/td7TMEdemmIfsDGyEfEJaQP4P61f4L7vN+tqi968SgwFveezvYem4CvevNQ1Rm4PxUXeuv4txe/P/HVprb3o9movoLAGGNaBBFZCzykqr9OdCzNndUgjDHGRGUJwhhjTFR2iMkYY0xUVoMwxhgTVYu5zLVTp07ao0ePBi+/d+9e2rRp03gBNTKLLz4WX3wsvvgkc3zz5s3bpqq5UWcmuq2PxnoMHTpU4zF79uy4lg+axRcfiy8+Fl98kjk+YK5aW0zGGGPqwxKEMcaYqCxBGGOMiarFnKQ2xhydKioqyMrKYvny5G3mKCcnJ+HxZWZmUlBQQHp6TL0bA5YgjDHNXHFxMfn5+RQUFCCHenpNKiUlJWRnJ647CFVl+/btFBcX07Nnz5iXs0NMxphmraysjJycnKRNDslAROjYsSNlZWV1F/YJNEGIyBgRWel1sD4lyvyzxHUWXyki4yLmHSsib4rIcq/Xrx5BxmqMab4sOdStIfsosAThdSf5MK653P7AVSIS2UPVOlyT0X/nSE8C96vqCbhOabYEEeeesgp+9/Yq1uyuCmL1xhjTbAVZgxgOFKnqGlUtB6bh2mA/SFXXqmv//7A21r1Ekqaqb3nlSjWGTjoaQhV+9/anrNoRazPvxhhzuKysrESHEIggT1J3A77wjRcDp8a4bF9gl9ejWE9cpxtTVPWwv/leT2aTAPLz8yksLKx3kKpKWgpsKz3QoOWbSmlpqcUXB4svPskcX05ODlVVVZSUNGYPr/VX2/aTIT5w52vq9T7WdIt1vA9gHPCob/xaXCce0co+AYyLWHY30AuXxF4Cbqxte/E0tXHGfe/oVb9/o8HLN4VkvlVf1eKLl8XXcMuWLdM9e/YkNIY2bdqoqmo4HNY77rhDBwwYoAMHDtRp06apquqqVat0xIgRetJJJ+mAAQP03Xff1crKSp04ceLBsg888EDgcS5btuyIadTS1EaQNYj1uO4aqxV402JRDCxQ1TUAIvIqrm/ivzZqhJ7c7BC79x4IYtXGmCb0038uZdmGPY26zv5d2/KTSwbEVPbll19mwYIFLFy4kG3btnHKKadw1lln8cILL3DBBRdw1113UVVVxb59+1iwYAHr169nyZIlAOzatatR424MQZ6DmAP0EZGeIpIBTACm12PZdiJS3cLgObh+eAORmxVi9wHrF8MYE5/333+fq666itTUVPLz8zn77LOZM2cOQ4YM4fHHH2fq1KksXryY7OxsevXqxZo1a7jlllt44403aNu2baLDP0JgNQhVrRSRycBMIBV4TFWXisg9uCrNdBE5BdeBenvgEhH5qaoOUNUqEbkDeEfctVnzgL8EFWtutiUIY1qCWP/pN7UzzjiDd999l9dee43rr7+e22+/neuuu46FCxcyc+ZM/vSnP/H888/z2GOPJTrUwwR6J7WqzgBmREy72zc8B3foKdqybwEnBhlftbzsTEoqoKIqTHqq3TtojGmYESNG8Oc//5mJEyeyY8cO3n33Xe6//37WrVvH8ccfzze/+U0OHDjA/Pnzueiii8jIyODyyy+nX79+XHPNNYkO/wjW1AauBgHuSqYuOa0SHI0xprm69NJL+fDDDznppJMQEX71q1/RuXNnXn31VcaPH096ejpZWVk8+eSTrF+/nhtuuIFw2F1i/4tf/CLB0R/JEgSHEsTWEksQxpj6Ky0tBdzdyvfffz/333//YfOvvvpqbrrppiOWmz9/fpPE11B2PAXI8yUIY4wxjiUIDtUgtliCMMaYgyxBAB2zMgCrQRhjjJ8lCCCUlkqbdEsQxhjjZwnC0y4kliCMMcbHEoQnJyRsKalfZxrGGNOSWYLw5GQIW0utBmGMMdUsQXhyQilsLTlQ3ZqsMcYEora+I9auXcvAgQObMJraWYLw5ISEsoowJQcqEx2KMcYkBbuT2pMTcv21bi05QNvM9ARHY4xpkNenwKbFjbvOzoPgwvtqnD1lyhSOOeYYvv3tbwMwdepU0tLSmD17Njt37qSiooK77rqLCRMm1GuzZWVl3HzzzcydO5e0tDQeeOABRo0axdKlS7nhhhsoLy8nHA7z0ksv0bVrV6688kqKi4upqqrixz/+MePHj4/rZYMliIPa+RLEcbkts/tAY0zjGz9+PLfddtvBBPH8888zc+ZMvvOd79C2bVu2bdvG8OHDGT9+PK5x6tg8/PDDiAiLFy9mxYoVnH/++axatYo//elP3HrrrVx99dWUl5dTVVXFjBkz6Nq1K6+99hoAu3fvbpTXZgnC469BGGOaqVr+6Qdl8ODBbNmyhQ0bNrB161bat29P586d+e53v8u7775LSkoKGzduZPPmzXTu3Dnm9b7//vvccsstABx//PF0796dVatWcfrpp3PvvfdSXFzMZZddRp8+fRg0aBDf+973+P73v8/FF1/MiBEjGuW12TkIT06GSxDW3IYxpr6uuOIKXnzxRZ577jnGjx/PM888w9atW5k3bx4LFiwgLy+PsrLGuYz+a1/7GtOnT6dVq1ZcdNFFzJo1i759+zJ//nwGDRrEj370I+65555G2VagCUJExojIShEpEpEpUeafJSLzRaRSRMZFmd9WRIpF5KEg4wRokw4ZqSlWgzDG1Nv48eOZNm0aL774IldccQW7d+8mLy+P9PR0Zs+ezbp16+q9zhEjRvDMM88AsGrVKtatW0e/fv1Ys2YNvXr14jvf+Q5jx45l0aJFbNiwgdatW3PNNddw5513NlorsYEdYhKRVOBhYDSuj+k5IjJdVf1dh64DrgfuqGE1/we8G1SMfiJCbnbIEoQxpt4GDBhASUkJ3bp1o0uXLlx99dVccsklDBo0iGHDhtG3b996r/Nb3/oWN998M4MGDSItLY0nnniCUCjE888/z1NPPUV6ejqdO3fmhz/8IXPmzOHOO+8kJSWF9PR0/vjHPzbK6wryHMRwoEhV1wCIyDRgLL6+pVV1rTcvHLmwiAwF8oE3gGEBxnlQp+yQ3U1tjGmQxYsPXT3VqVMnPvzww4PjJSUlZGdnA4f6joimR48eLFmyBIDMzEwef/zxI8pMmTKFKVMOPyBzwQUXcMEFF8QVfzRBJohuwBe+8WLg1FgWFJEU4DfANcB5tZSbBEwCyM/Pp7CwsKGxUlpaSsqBNNbu0rjWE5TS0tKkjKuaxRcfi6/hcnJyqKqqoqSkJNGh1ChZ4isrK6vX+5isVzF9C5ihqsW1XRamqo8AjwAMGzZMR44c2eANFhYWckLPjry5dBPxrCcohYWFSRlXNYsvPhZfwy1fvpzU1NSD/9CTkb8GAa62ce211x5WJhQK8fHHHwcaR2ZmJoMHD465fJAJYj1wjG+8wJsWi9OBESLyLSALyBCRUlU94kR3Y8rNCrF9bzmVVWHSUu0CL2Oai+bWRM6gQYNYsGBBk26zIfsoyAQxB+gjIj1xiWEC8LVYFlTVq6uHReR6YFjQyQFcz3KqsH1vOfltM4PenDGmEWRmZrJ7926ys7PrdSPa0URV2b59O5mZ9ftdCyxBqGqliEwGZgKpwGOqulRE7gHmqup0ETkFeAVoD1wiIj9V1QFBxVSXXF/f1JYgjGkeCgoKWLhwYa0nfxOtrKys3j/OjS0zM5OCgoJ6LRPoOQhVnQHMiJh2t294Du7QU23reAJ4IoDwjpDnSxDGmOYhPT2d0tJShg1rkosdG6SwsLBex/6ThR1o96muQdilrsYYYwniMJ2yrAZhjDHVLEH4ZKanktMq3RKEMcZgCeIIudkha7DPGGOwBHGE3Cxrj8kYY8ASxBFys0NsLbUEYYwxliAi5FmLrsYYA1iCOEJudoh95VWUHqhMdCjGGJNQliAi5NrNcsYYA1iCOEJetrsd3hKEMeZoZwkigt1NbYwxjiWICHaIyRhjHEsQEdq1SictRSxBGGOOepYgIqSkiLsXwhKEMeYol6xdjiaUNbdhjElaZbthzwbYs9573gCZ7eC0mxp9U5YgosjNCrFxt52kNsY0IVXYv/PQj74/AfiHy0uOXLbHiOaXIERkDPB7XI9yj6rqfRHzzwJ+B5wITFDVF73pJwN/BNoCVcC9qvpckLH65bUNsWj97qbanDHmaKIKu7+AjQsPPXascT/+FfsOLyspkNUZ2naF3H5w3DluuG1XaNvNPWd3gbSMQEINLEGISCrwMDAaKAbmiMh0VV3mK7YOuB64I2LxfcB1qvqpiHQF5onITFXdFVS8frlZIbaXHqAqrKSmWB+3xpgGCodh52fkbnkP3pp1KCHs3+nmSwrkHg/5A6HvmCN//LM6Q2riDvQEueXhQJGqrgEQkWnAWOBgglDVtd68sH9BVV3lG94gIluAXKBpEkR2iLDC9r0HDt44Z4wxtaqqhO2fHl4z2LgIyksYAJCSDvn94YRLoMtJ0OVkyOsPGa0THXmNgkwQ3YAvfOPFwKn1XYmIDAcygNVR5k0CJgHk5+dTWFjYoEABSktLDy6/eZNrh+n12R/QvW1qg9fZmPzxJSOLLz4WX3yaMr6UqjJa7d9Eq/0bDz7a7P2crNLPSA2XA1CVkkFpVk9KO42gJPs4tqR2Rjv1Q1PS3Ur2AkWlUPTfJom5oZL6JLWIdAGeAiaqajhyvqo+AjwCMGzYMB05cmSDt1VYWEj18tmf7+ShBf+he79BjOyX1+B1NiZ/fMnI4ouPxRefRo+vbDfs+MydG9ix5vDh0k2Hl23dyZ0f6H+eVzM4idSOvclJTSPHK7IpyfdfTYJMEOuBY3zjBd60mIhIW+A14C5V/aiRY6tV3sHmNuxSV2NaJFXYt9398O/8LCIZrIF92w4vn90F2veE3udBh57QoZf36AmZOdG30QIEmSDmAH1EpCcuMUwAvhbLgiKSAbwCPFl9ZVNTsuY2jGkBqird1UI7P4Oda33JYK0bP+xyUYGcAveDf8LFvgTQC9r3gIw2CXkJiRZYglDVShGZDMzEXeb6mKouFZF7gLmqOl1ETsElgvbAJSLyU1UdAFwJnAV0FJHrvVVer6oLgorXLzM9lezMNEsQxiS7qkrYXkSnrR/CB4sOTwa7v4Cwr1+X1Az3Y9++J3T/kksG7Xu653bdId0uSIkU6DkIVZ0BzIiYdrdveA7u0FPkck8DTwcZW12suQ1jkkzZHti8FDYths2L3fOW5VBZxkCApbg7ijv0hK4nw4BLD08C2V0hxVoXqo+kPkmdSLlZliCMSQhV2LUONi9xSaD6sevzQ2VadYDOA+GUb0D+QOatK2Xo6HHQqn3i4m6BLEHUIDc7xNINexIdhjEtW1UlbFnm7hmoTgibl7iriAAQdx6g62AYci10PtHdVNa2K8ihm1hLdhVacgiAJYga5GVnUliyNdFhGNOy7NkAxXOgeC6snwcbPjnUvER6a8gfAAMvd0mg84mQdwKEshIb81HMEkQNcrNDlB6oZF95Ja0zbDcZU2/le2HDApcQ1s+F4nlQssHNS82AzoNgyHXQbZirIXToCSnJcWOqceyXrwb+S127d7TdZEytwmHYtspLBN5jyzLQKje/fQ935VDBKVAwzCWHtFBCQzZ1s1++GuQdliCOzmugjYmqogy2rnBXFFWfN9i4EA545+xCbaHbUBhxu6sdFAyDNp0SG7NpEEsQNci1u6nN0U4VSjbCpiUc+/l0ePFJlxS2fXqoZpDWyp0nGHj5odpBxz52OWkLYQmiBnY3tTmqVJTB1uXefQZLXM1g81LYvwOAXgA5x7iTx8df7C4xzR/orjCy8wYtliWIGnRonUFqiliCMC1HxX7Y+fmhtocin/21gvz+rsmJ/EGQP4D3P93JmaMvTmz8pslZgqhBSorQKSvDEoRpXvbtiPjhX3tovPoKomoZ2dChh+uToP9XvVrBoKhXE1WuLWyqV2CSiCWIWuRmh9hSYn1TmyRVvg9Wz4JVr7vDQTs+g7KIPrWy8l1TE73OPtTkRPVz646H3WxmTCRLELXIzQqxtdRqECaJ7N0GK1+HlTNccqgsg1AOFAyFgUMOTwBHcSukpnFYgqhFXnYmyzZacxsmwbavhhWvuaTwxcegYWhbAEMmwvEXQfczIDU90VGaFsgSRC1ys0NsKy2nKqykplhV3DSRcNg1QbHyNZcYtq5w0/MHwVl3wvFfds1Q2OEhEzBLELXIzQ5RFVZ27iunU5bd9WmCI+EK+PRtlxRWvu7uP5BUd/fx0Ouh30XQvnuiwzRHGUsQtfDfC2EJwjS6nWthTSGsnsUZK9+Eqv2Q3gZ6n+tqCX3Oh9YdEh2lOYoFmiBEZAzwe1yPco+q6n0R888CfgecCEzwdy8qIhOBH3mjP1PVvwUZazT+5jZO6NLUWzctzv5d8Nm7sGY2rJ7tLj8FyO7Klrwz6Trqm9DzbOvZzCSNwBKEiKQCDwOjgWJgjohMV9VlvmLrgOuBOyKW7QD8BBgGKDDPW3ZnUPFGY81tmLhUlruWTKsTwob57gRzRhb0OBNOvQmOGwWd+rLq3/+ma9+RiY7YmMMEWYMYDhSp6hoAEZkGjAUOJghVXevNC0csewHwlqru8Oa/BYwBng0w3iNYcxumXlRdi6arZ7tLUD//AMpLQVK8xuvucAmh2zBIy0h0tMbUKcgE0Q34wjdeDJwax7LdIguJyCRgEkB+fj6FhYUNChSgtLQ06vKZqfDJ8iIKDwun6dUUX7I4GuNLqyil1f71tNn7BTm7l9Jhx0JC5dsB2J/ZmR2dRrCz/UnsajeIynSv05vPyuGz/zRJfI3J4otPssdXk2Z9klpVHwEeARg2bJiOHDmywesqLCwk2vJd5haSkdOWkSOHNHjdjaGm+JJFi40vHIbdX7gWTLet8h6fwvZPoXTzoXKZ7aD32dBrFBw3ilbte9CNKP9qGju+JmLxxSfZ46tJkAliPXCMb7zAmxbrsiMjli1slKjqKTcrZIeYjgbl+2B70aEEcDARFEHl/kPlMttBp77QezR06uOGO/WxVk1NixRkgpgD9BGRnrgf/AnA12JcdibwcxGp7oX8fOAHjR9i3XKzQyzfZHdTt0i7i2HhNFj8wqGb0QAQd89Bp76uDaODiaCvtV9kjiqBJQhVrRSRybgf+1TgMVVdKiL3AHNVdbqInAK8ArQHLhGRn6rqAFXdISL/h0syAPdUn7BuarnZId791GoQLUb5Xlj+L1jwjLvkFIVjvwQjfwi5XhLo0AvSWyU6UmMSLtBzEKo6A5gRMe1u3/Ac3OGjaMs+BjwWZHyxyM0OUVJWSVlFFZnpdgihWQqHydm1BF59AZa96q4satcdzv4+nDTBNWxnjDlCsz5J3RT8l7oe06F1gqMx9bLjM3cIaeGzDN71ubv/YMBX4aSvwbGnW7eYxtTBEkQd8nw3y1mCaAbK9sCyf8CCv8O6/wACvc5meefLOOGyO635a2PqwRJEHQ7VIKzjoKQVrnLnExb8HZb/01111LEPnHs3nDgecgrYXFjICZYcjKkXSxB1sLupk1TlAZcUVs441PppZg6cfJU7hFQwzK42MiZOliDq0LFNiBSxBJEU9u2AT99yTWIXveNONle3fjrgUtcktjV0Z0yjsQRRh9QUoaN1PZo4O9fCihmupvD5f0CrIKszDLrCNYndY4QlBWMCYgkiBrlZIbbssQTRJMJh2PiJO2y0YgZsWeqm554AZ94G/b4MXQfbFUjGNAFLEDHIzbYaRKAqD8Bn70X0ppbibmC74OfQ70J385oxpklZgvP8BjwAAB2qSURBVIhBXnaIVZtLEh1Gy1BZDluXw4YFsHEBbFwIm5ZA1QHvfMI5rpbQ9wLrTc2YBLMEEYPcbNdgXzispKTYlTExqyiDLctcItjgJYMty6Cq3M0PtYUuJ8Hwb0LPs6w3NWOSjCWIGORmh6gMK7v2V9ChjXX0Ek1K1QEongsbPjlUM9iyHMKVrkBmO5cMTrvZPXc5Gdr3tHMJxiQxSxAx8N8LYQnCp2y3awn1k2cYsWEBvOd1DNiqA3Q9Gb402iWDrie7to/svgRjmpWYEoSI3Ao8DpQAjwKDgSmq+maAsSWNvGx32GNryQH6dc5OcDQJpgrr58G8x2HJy1CxDzoP4vPu4+hx2ldczSCnwJKBMS1ArDWIr6vq70XkAlzT3NcCTwFHRYLIPdge01Hc3Mb+Xa62MO8J2LzEnVAedAUMvR66Dmbtv/9NjxNGJjhIY0xjijVBVP8dvAh4yuvX4aj5i3jUNrehCsVzXFJY8rJr46jLyXDx72DQOAgd5bUpY1q4WBPEPBF5E+gJ/EBEsoFwXQuJyBjg97gOgx5V1fsi5oeAJ4GhwHZgvKquFZF03KGsIV6MT6rqL2KMtdFlhdJonZF69CSI/Tth4XMuMWxd7prJPmkCDJ3oblIzxhwVYk0QNwInA2tUdZ+IdABuqG0BEUkFHgZGA8XAHBGZrqrLIta7U1V7i8gE4JfAeOAKIKSqg0SkNbBMRJ5V1bX1eXGNKTc7xJaWnCBUYd1HLiksexUqy6DbUPjKH2DAZRDKSnSExpgmFmuCOB1YoKp7ReQa3D/739exzHCgSFXXAIjINGAs4E8QY4Gp3vCLwEPeoSsF2ohIGtAKKAcS2jF0blaoZdYgKstdUpjzKGxb6e5NGHwNDJkIXU5MdHTGmAQSVa27kMgi4CTgROAJ3OGfK1X17FqWGQeMUdVveOPXAqeq6mRfmSVemWJvfDVwKrAbdxL8XKA18F1VfSTKNiYBkwDy8/OHTps2LYaXHF1paSlZWTX/S37okzI2lIb5+YjEdBpUV3wN0WH7fHoX/YXW+zewJ7svG7pewJa8Mwmn1v9mtSDia0wWX3wsvvgkc3yjRo2ap6rDos5U1TofwHzv+W7gRv+0WpYZhzvvUD1+LfBQRJklQIFvfDXQCTgDeAZIB/KAlUCv2rY3dOhQjcfs2bNrnX/3q4v1xKkz49pGPOqKr162r1H9+wTVn7RV/f1g1VVvxr3KRo0vABZffCy++CRzfMBcreF3NdZDTCUi8gPvR36EiKR4P961WQ8c4xsv8KZFK1PsHU7KwZ2s/hrwhqpWAFtE5ANgGLAmxngbXW52iN37KyirqCIzPTVRYcSnfC+8/1v44EFISYPzpsJp34K0UKIjM8YkoVjbORgPHMDdD7EJ92N/fx3LzAH6iEhPEckAJgDTI8pMByZ6w+OAWV5GWwecAyAibYDTgBUxxhqI6ktdtzXHVl1V3WWqDw2Hd++H/l+BW+bCmd+15GCMqVFMCcJLCs8AOSJyMVCmqk/WsUwlMBmYCSwHnld3/8Q9IvIVr9hfgY4iUgTcDkzxpj8MZInIUlyieVxVF9XztTUq/93UzcrmZfC3S+DFG6B1e7jhDbj8UWjbNdGRGWOSXKxNbVyJqzEU4m6a+4OI3KmqL9a2nKrOAGZETLvbN1yGu6Q1crnSaNMT6dDd1M0kQezfBbN/7q5OymwLX/4NDL0BUprp4TFjTJOL9RzEXcApqroFQERygbdxl6YeFZrN3dThMHzyFLzzU3fD29Ab4JwfWd8Kxph6izVBpFQnB892Yj9/0SJ0bJOBSJIniC/mwOt3uia3jz0dLvyla03VGGMaINYE8YaIzASe9cbHE3HoqKVLS02hY5uM5DzEVLIZ3p4KC/8OWZ3hsr+4hvSOnuayjDEBiClBqOqdInI57v4EgEdU9ZXgwkpOnZLpburSrbDqdVjxGqwphHAVnHEbnHWHNaJnjGkUMXcYpKovAS8FGEvSy80OsTWRl7luX+0SworX4IuPAYWcY12T26d8Ezr1TlxsxpgWp9YEISIluHaRjpgFqKq2DSSqJJWXncmardubboPhMGz8BFa8xinzXoDCdW5650Ewcgr0u8gN26EkY0wAak0QqmrHKnxys90hJlUlsO4wKsth7XuulrDydSjZAJJKeU5/2pz1S+h3IbTvHsy2jTHGx/qkrofc7BDlVWF276+gXetG7Ju6bA8UvQUrZsCnb8KBPZDeGnqfC8f/BPqcz8L/LmLkaSMbb5vGGFMHSxD1kOe7F6LREsSqN+GlG11SaN0J+o+F478MvUZCeqvG2YYxxjSAJYh68N9N3Sc/zqNvqvDR/4M3fwT5A+HCX8Exw+1OZ2NM0rAEUQ+Ndjd1ZTnMuAPm/w1OuAQu/TNktGmECI0xpvFYgqiHRkkQ+3bA89e5E9Ej7oBRd0HKUXVTujGmmbAEUQ/ZoTQy01Mafi/E1lXw9ythzwZ3t/OJVzZugMYY04gsQdSDiJCbHWLLnrL6L1z0DrxwA6RlwPX/cucbjDEmidmxDYBP3yKlKrZaQW5WA+6m/vgReOYKaHcMfHOWJQdjTLNgNYjtq+GZcZyelgUVE2HY12ttsiIvO5M120pjW3dVBbwxxfXJ0O8id1gplJwdlxtjTKRAaxAiMkZEVopIkYhMiTI/JCLPefM/FpEevnknisiHIrJURBaLSGYgQXboBRP/xc72J8F//wwPDYUnx8Ky6VBVeUTx3OxQbC267t8JT1/uksMZt8L4py05GGOalcBqECKSius6dDRQDMwRkemqusxX7EZgp6r2FpEJwC+B8SKSBjwNXKuqC0WkI1ARUKDQcwTLBlSRN/QE+ORJmPsEPH8tZHdxDeENue5gF5252SF27avgQGUVobQa7lnYVgTPjoedn8PY/weDrw4kdGOMCVKQNYjhQJGqrlHVcmAaMDaizFjgb97wi8C54ho5Oh9YpKoLAVR1u6pWBRirk50PZ90Jty2CCc9C/gAovA9+OxCeuwZWzyY3Kx2A7aXl0dexphAePcfVICb+05KDMabZEtVojbU2wopFxgFjVPUb3vi1wKmqOtlXZolXptgbXw2cClwDDAXygFxgmqr+Kso2JgGTAPLz84dOmzatwfGWlpaSlXXkIaDM/RvpumEmXTa+TXplCTszuvDQ3nPpOWQ0BR3bHVa2y4Y36Lvqz+xrXcDiQT+irFV+g+OJNb5kYfHFx+KLj8XXcKNGjZqnqsOizlTVQB7AOOBR3/i1wEMRZZYABb7x1UAn4A7gM2+4NfAhcG5t2xs6dKjGY/bs2bUXKN+vumCalj48SvUnbbXynlzVV25WLZ6rWlmhOuN/VX/SVvXpcar7d8cVS4PiSzCLLz4WX3wsvoYD5moNv6tBXsW0HjjGN17gTYtWptg775CD6++6GHhXVbcBiMgMYAjwToDx1i49E04az54eX2HcfY/zYO/59Fn6Kix4Btrkwt6tcPpkGH2PtadkjGkRgjwHMQfoIyI9RSQDmABMjygzHZjoDY8DZnkZbSYwSERae4njbGAZSaBTVojl2p0Z3b8P31sBF/0aOvaGr/wBLrjXkoMxpsUIrAahqpUiMhn3Y58KPKaqS0XkHlyVZjrwV+ApESkCduCSCKq6U0QewCUZBWao6mtBxVof6akpdGiTwZaSMshsC8O/6R7GGNPCBHqjnKrOAGZETLvbN1wGXFHDsk/jLnVNOrlZofhbdDXGmCRnTW00QG52A5rbMMaYZsYSRAPkZVsNwhjT8lmCaIDq5jY0oHtIjDEmGViCaIDc7BDllWH2lB3ZVpMxxrQUliAaoNG6HjXGmCRmCaIBqhPElpIGdBxkjDHNhCWIBsizGoQx5ihgCaIBcrNc1xSWIIwxLZkliAZo2yqNjLQUuxfCGNOiWYJoABFxd1PvsQRhjGm5LEE0kN1NbYxp6SxBNJDdTW2MaeksQTRQ9d3UxhjTUlmCaKDc7BA79pZTURVOdCjGGBMISxANVH2z3PbS8gRHYowxwQg0QYjIGBFZKSJFIjIlyvyQiDznzf9YRHpEzD9WREpF5I4g42yIvGy7F8IY07IFliBEJBV4GLgQ6A9cJSL9I4rdCOxU1d7Ab4FfRsx/AHg9qBjjYc1tGGNauiBrEMOBIlVdo6rlwDRgbESZscDfvOEXgXNFRABE5KvAZ8DSAGNsMGuwzxjT0gWZILoBX/jGi71pUcuoaiWwG+goIlnA94GfBhhfXDplZQCWIIwxLVegfVLHYSrwW1Ut9SoUUYnIJGASQH5+PoWFhQ3eYGlpab2Xb5MOn6xcQ2Hq+gZvN1YNia8pWXzxsfjiY/EFRFUDeQCnAzN94z8AfhBRZiZwujecBmwDBHgPWOs9dgE7gMm1bW/o0KEaj9mzZ9d7mfN+U6j/8+TcuLYbq4bE15QsvvhYfPGx+BoOmKs1/K4GWYOYA/QRkZ7AemAC8LWIMtOBicCHwDhglhfwiOoCIjIVKFXVhwKMtUGsuQ1jTEsW2DkIdecUJuNqCcuB51V1qYjcIyJf8Yr9FXfOoQi4HTjiUthkZs1tGGNaskDPQajqDGBGxLS7fcNlwBV1rGNqIME1AtfcRhmqSm3nSowxpjmyO6njkJsdoqwiTOmBykSHYowxjc4SRBzsbmpjTEtmCSIOh+6mtgRhjGl5LEHEwe6mNsa0ZJYg4pCbZQnCGNNyWYKIQ7vW6aSnit0LYYxpkSxBxEFEyM0KsWWPJQhjTMtjCSJOdje1MaalsgQRp9zsTDsHYYxpkSxBxCk3O8RW6zTIGNMCWYKIU252iO17y6msCic6FGOMaVSWIOKUmx1CFXbsLU90KMYY06gsQcQpz+6mNsa0UJYg4mR3UxtjWipLEHGqvpt64247UW2MaVksQcSpS04m3dq14k//Xs2esopEh2OMMY0m0AQhImNEZKWIFInIEb3FiUhIRJ7z5n8sIj286aNFZJ6ILPaezwkyznikpabw4FUns37Xfn748uLqvraNMabZCyxBiEgq8DBwIdAfuEpE+kcUuxHYqaq9gd8Cv/SmbwMuUdVBuD6rnwoqzsYwtHsHbh/dl38t2shzc75IdDjGGNMogqxBDAeKVHWNqpYD04CxEWXGAn/zhl8EzhURUdVPVHWDN30p0EpEQgHGGrebzz6OM3t3Yuo/l7Jqc0miwzHGmLhJUIdERGQcMEZVv+GNXwucqqqTfWWWeGWKvfHVXpltEeu5SVXPi7KNScAkgPz8/KHTpk1rcLylpaVkZWU1eHmAXQfC3P3BfrIzhLtPb0UotfH6qW6M+IJk8cXH4ouPxddwo0aNmqeqw6LOVNVAHsA44FHf+LXAQxFllgAFvvHVQCff+ABv2nF1bW/o0KEaj9mzZ8e1fLV/r9yi3b//L53y0sJGWV+1xoovKBZffCy++Fh8DQfM1Rp+V4M8xLQeOMY3XuBNi1pGRNKAHGC7N14AvAJcp6qrA4yzUZ3VN5ebRx7Hs//9gn8u3FD3AsYYk6SCTBBzgD4i0lNEMoAJwPSIMtNxJ6HB1ThmqaqKSDvgNWCKqn4QYIyBuH10X4Yc244fvLyYddv3JTocY4xpkMAShKpWApOBmcBy4HlVXSoi94jIV7xifwU6ikgRcDtQfSnsZKA3cLeILPAeeUHF2tjSU1N48KrBpAhMfnY+5ZXWkJ8xpvlJC3LlqjoDmBEx7W7fcBlwRZTlfgb8LMjYglbQvjW/GnciNz09n/tnruCuL0de4WuMMcnN7qQO0JiBXbj2tO785b3PmLVic6LDMcaYerEEEbC7vnwCx3fO5o4XFrHJ2msyxjQjliAClpmeykNfG8L+8ipue+4TqsLWFIcxpnmwBNEEeudl8X9fHchHa3bw0KyiRIdjjDExsQTRRC4f0o1LB3fj9++s4qM12xMdjjHG1MkSRBMREf7vqwPp3rENt01bYF2UGmOSniWIJpQVSuMPVw1mx95y7nxhoTUNboxJapYgmtjAbjn88KLjeWfFFh77YG2iwzHGmBpZgkiAiV/qwej++dz3+nIWFe9KdDjGGBOVJYgEEBHuH3ciuVkhbnn2E0qsq1JjTBKyBJEg7Vpn8OBVgyneuZ+7Xlli5yOMMUkn0LaYTO2G9ejAd8/rw6/fXMWesgrGDOjMuSfkk5ud1J3nGWOOEpYgEuzmkb05UBnmlU/WM2XlYkQWM/TY9ozun8/5AzrTs1ObRIdojDlKWYJIsNQU4Xvn9+P20X1ZvrGEt5Zt5s1lm/jF6yv4xesr6J2Xxej++XQqq+KssJKS0njdmBpjTG0sQSQJEaF/17b079qWW8/rQ/HOfby9bDNvLd/MI++uoSqs/HnpO5zXP5/R/fP50nEdCaWlJjpsY0wLZgkiSRW0b831Z/Tk+jN6sntfBQ+/+m+KtT3/+GQ9f/94HW0yUhnZL4/zB+Qzsl8eOa3SEx2yMaaFCTRBiMgY4PdAKvCoqt4XMT8EPAkMxfVFPV5V13rzfgDcCFQB31HVmUHGmsxyWqfzpa5pjBw5lLKKKj5cvZ03l23mrWWbeW3xRlJThPzsEO1aZ9CudTrtI57btc6gvfdcPT2nVTqpdrjKGFOLwBKEiKQCDwOjgWJgjohMV9VlvmI3AjtVtbeITAB+CYwXkf64PqwHAF2Bt0Wkr6pWBRVvc5GZnsqo4/MYdXwe9351IAuKdzF7xRY27Cpj175ydu4rZ/mmPezaV8GufeXU1rp428w02rfJoF3rDFqlp5CemkIozT1n+J4zDo4LGamppKfJwWkZqa7cqg2VlCzcQGqKkCJCaoqQliKkpAipIqSkQKo3vXqav2xqCoCQIpAigvieRXzTOTTufxbh4Dz3DEL18lAZViqqwkeWEUuSxtQkyBrEcKBIVdcAiMg0YCzgTxBjgane8IvAQ+K+sWOBaap6APjM67N6OPBhgPE2OykpwpBj2zPk2PZR54fDSsmBSnbtK2fXvgp2es8ukbjnXfsr2LmvgrKKKkrKKtlRFaa8MkyF91xepZRXVlFRpZRXhWvvz2LRJwG90kby5utRJ1cnFzd8KHmASzIcNv9Q4nHzDy1zcAKHr4/D1hcx3RuvqCgn4/23/FEdFt+RUyOnH57oIvNeZBqMNTFWFysrKyPz41lR1x1t+zWtp8b5dcZRe4n9+/bRem5hHWuJI4A4F9+3bx+t5xXWvo44/qyc0KUtf7hqcIOXr0mQCaIb8IVvvBg4taYyqlopIruBjt70jyKW7Ra5ARGZBEwCyM/Pp7CwsMHBlpaWxrV80Borvnbeo0c6kOM9ohLckUHwf0zCqlSGoSIMVWGoCLvx0r37yGzdmrC6MqpQpXjj7qHe8uGI6WFA1XvgPVS9Zzefg8tXx+HG8S/vxahe4UPrggPl5WRkZFB9P2L1dPDW79vGwdHI8YPL6MFxDtvu4arLHjE9YmMKVFQo6enhI9ejUQePWOeR261lfj3LA1Skh0lPq4i63SNfYR0brN/sOqlCZeswaWkN67GxKW5RzWkVJi215vji3gclBwL5/WrWJ6lV9RHgEYBhw4bpyJEjG7yuwsJC4lk+aBZffCy++Fh88Un2+GoSZFMb64FjfOMF3rSoZUQkDfd/dnuMyxpjjAlQkAliDtBHRHqKSAbupPP0iDLTgYne8DhglrpGiaYDE0QkJCI9gT7AfwOM1RhjTITADjF55xQmAzNxB7MfU9WlInIPMFdVpwN/BZ7yTkLvwCURvHLP405oVwLftiuYjDGmaQV6DkJVZwAzIqbd7RsuA66oYdl7gXuDjM8YY0zNrLlvY4wxUVmCMMYYE5UlCGOMMVFZgjDGGBOVtJSuLkVkK/B5HKvoBGxrpHCCYPHFx+KLj8UXn2SOr7uq5kab0WISRLxEZK6qDkt0HDWx+OJj8cXH4otPssdXEzvEZIwxJipLEMYYY6KyBHHII4kOoA4WX3wsvvhYfPFJ9viisnMQxhhjorIahDHGmKgsQRhjjInqqEoQIjJGRFaKSJGITIkyPyQiz3nzPxaRHk0Y2zEiMltElonIUhG5NUqZkSKyW0QWeI+7o60r4DjXishib/tzo8wXEXnQ24eLRGRIE8bWz7dvFojIHhG5LaJMk+5DEXlMRLaIyBLftA4i8paIfOo9R+0zVkQmemU+FZGJ0coEFN/9IrLCe/9eEZF2NSxb62chwPimish633t4UQ3L1vp9DzC+53yxrRWRBTUsG/j+i5uqHhUPXJPjq4FeQAawEOgfUeZbwJ+84QnAc00YXxdgiDecDayKEt9I4F8J3o9rgU61zL8IeB3XZ+lpwMcJfL834W4CStg+BM4ChgBLfNN+BUzxhqcAv4yyXAdgjffc3htu30TxnQ+kecO/jBZfLJ+FAOObCtwRw/tf6/c9qPgi5v8GuDtR+y/ex9FUgxgOFKnqGlUtB6YBYyPKjAX+5g2/CJwr8fQkXg+qulFV53vDJcByovTD3QyMBZ5U5yOgnYh0SUAc5wKrVTWeu+vjpqrv4vo68fN/zv4GfDXKohcAb6nqDlXdCbwFjGmK+FT1TVWt9EY/wvXomBA17L9YxPJ9j1tt8Xm/HVcCzzb2dpvK0ZQgugFf+MaLOfIH+GAZ7wuyG+jYJNH5eIe2BgMfR5l9uogsFJHXRWRAkwbmKPCmiMwTkUlR5seyn5vCBGr+YiZ6H+ar6kZveBOQH6VMsuzHr+NqhNHU9VkI0mTvENhjNRyiS4b9NwLYrKqf1jA/kfsvJkdTgmgWRCQLeAm4TVX3RMyejztkchLwB+DVpo4POFNVhwAXAt8WkbMSEEOtxHVx+xXghSizk2EfHqTuWENSXmsuInfhenR8poYiifos/BE4DjgZ2Ig7jJOMrqL22kPSf5eOpgSxHjjGN17gTYtaRkTSgBxge5NE57aZjksOz6jqy5HzVXWPqpZ6wzOAdBHp1FTxedtd7z1vAV7BVeX9YtnPQbsQmK+qmyNnJMM+BDZXH3bznrdEKZPQ/Sgi1wMXA1d7SewIMXwWAqGqm1W1SlXDwF9q2G6i918acBnwXE1lErX/6uNoShBzgD4i0tP7hzkBmB5RZjpQfbXIOGBWTV+OxuYdr/wrsFxVH6ihTOfqcyIiMhz3/jVlAmsjItnVw7iTmUsiik0HrvOuZjoN2O07nNJUavznluh96PF/ziYC/4hSZiZwvoi09w6hnO9NC5yIjAH+F/iKqu6roUwsn4Wg4vOf07q0hu3G8n0P0nnAClUtjjYzkfuvXhJ9lrwpH7grbFbhrm64y5t2D+6LAJCJOyxRBPwX6NWEsZ2JO9SwCFjgPS4CbgJu8spMBpbirsj4CPhSE++/Xt62F3pxVO9Df4wCPOzt48XAsCaOsQ3uBz/HNy1h+xCXqDYCFbjj4Dfizmu9A3wKvA108MoOAx71Lft177NYBNzQhPEV4Y7fV38Oq6/s6wrMqO2z0ETxPeV9thbhfvS7RMbnjR/xfW+K+LzpT1R/5nxlm3z/xfuwpjaMMcZEdTQdYjLGGFMPliCMMcZEZQnCGGNMVJYgjDHGRGUJwhhjTFSWIIypg4hURbQS22gtg4pID39LoMYkk7REB2BMM7BfVU9OdBDGNDWrQRjTQF57/r/y2vT/r4j09qb3EJFZXmNy74jIsd70fK9/hYXe40veqlJF5C/i+gF5U0RaeeW/I65/kEUiMi1BL9McxSxBGFO3VhGHmMb75u1W1UHAQ8DvvGl/AP6mqifiGrp70Jv+IPBvdQ0FDsHdQQvQB3hYVQcAu4DLvelTgMHeem4K6sUZUxO7k9qYOohIqapmRZm+FjhHVdd4DS1uUtWOIrIN1/xDhTd9o6p2EpGtQIGqHvCtoweu34c+3vj3gXRV/ZmIvAGU4lqcfVW9RgaNaSpWgzAmPlrDcH0c8A1Xcejc4Jdx7VoNAeZ4LYQa02QsQRgTn/G+5w+94f/gWg8FuBp4zxt+B7gZQERSRSSnppWKSApwjKrOBr6Pa3r+iFqMMUGyfyTG1K1VRMfzb6hq9aWu7UVkEa4WcJU37RbgcRG5E9gK3OBNvxV4RERuxNUUbsa1BBpNKvC0l0QEeFBVdzXaKzImBnYOwpgG8s5BDFPVbYmOxZgg2CEmY4wxUVkNwhhjTFRWgzDGGBOVJQhjjDFRWYIwxhgTlSUIY4wxUVmCMMYYE9X/BxquGMbj5/v7AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, categorical_acc = shallow_mlp_model.evaluate(test_dataset)\n",
        "print(f\"Categorical accuracy on the test set: {round(categorical_acc * 100, 2)}%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyZPuD71o54_",
        "outputId": "df6642b1-8d98-4dd3-9a33-80ec009027e5"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1332 - categorical_accuracy: 0.8748\n",
            "Categorical accuracy on the test set: 87.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "- https://medium.com/the-owl/imbalanced-multilabel-image-classification-using-keras-fbd8c60d7a4b\n",
        "- https://link.springer.com/chapter/10.1007%2F978-3-642-40846-5_16\n",
        "- Descriptions for algorithms, process, and evaluation metrics: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
        "- Algorithms: https://scikit-learn.org/stable/modules/multiclass.html\n",
        "- Classifier chain: https://arxiv.org/abs/1912.13405, https://www.cs.waikato.ac.nz/~eibe/pubs/chains.pdf\n",
        "- Multilabel: https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/\n",
        "- Keras: https://keras.io/examples/nlp/multi_label_classification/"
      ],
      "metadata": {
        "id": "cmSZSTISUc9v"
      }
    }
  ]
}